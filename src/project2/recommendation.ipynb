{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema Interativo de Recomenda√ß√£o de Filmes\n",
    "\n",
    "**Objetivo**: Comparar 3 abordagens de recomenda√ß√£o + Interface interativa\n",
    "\n",
    "**Dataset**: MovieLens 990k ratings (HuggingFace)\n",
    "\n",
    "**Estrutura**:\n",
    "- **Parte 1 (C√©lulas 1-15)**: Implementa√ß√£o t√©cnica + m√©tricas\n",
    "- **Parte 2 (C√©lulas 16-21)**: Sistema interativo com Jupyter Widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTE 1: Implementa√ß√£o T√©cnica\n",
    "\n",
    "### Fase 1: Setup e An√°lise Explorat√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 1: Importa√ß√µes\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ML & Embeddings\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Widgets (Parte 2)\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "print(\"‚úÖ Todas as bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 2: Configura√ß√£o Global\n",
    "\n",
    "# === PATHS ===\n",
    "BASE_DIR = Path('.')\n",
    "CACHE_DIR = BASE_DIR / 'cache'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "\n",
    "for dir_path in [CACHE_DIR, RESULTS_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === PAR√ÇMETROS DE AVALIA√á√ÉO ===\n",
    "K = 10  # Top-K recomenda√ß√µes\n",
    "MIN_RATING_THRESHOLD = 3.0  # Considera \"relevante\" (ROBUSTA: era 4.0)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# === MODELOS ===\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L12-v2'  # 384-dim, ~120MB (ROBUSTA: era L6-v2)\n",
    "\n",
    "# === OTIMIZA√á√ïES DE MEM√ìRIA ===\n",
    "EMBEDDING_BATCH_SIZE = 64  # Mini-batches para embeddings (ROBUSTA: era 32)\n",
    "SIMILARITY_CHUNK_SIZE = 2000  # Processar 2000 filmes por vez (ROBUSTA: era 1000)\n",
    "TOP_K_SIMILAR = 2000  # Guardar top-150 similares por filme (ROBUSTA: era 100)\n",
    "\n",
    "# === PAR√ÇMETROS DO H√çBRIDO ===\n",
    "ALPHA_MIN_RATINGS = 5  # M√≠nimo de ratings para come√ßar a confiar no colaborativo\n",
    "ALPHA_MAX_RATINGS = 50  # M√°ximo para Œ± = 0.9\n",
    "\n",
    "print(\"‚úÖ Configura√ß√£o ROBUSTA completa!\")\n",
    "print(f\"   - Cache: {CACHE_DIR.resolve()}\")\n",
    "print(f\"   - Results: {RESULTS_DIR.resolve()}\")\n",
    "print(f\"   - Otimiza√ß√µes: Batch={EMBEDDING_BATCH_SIZE}, Chunks={SIMILARITY_CHUNK_SIZE}, Top-K={TOP_K_SIMILAR}\")\n",
    "print(f\"   - Modelo: {EMBEDDING_MODEL}\")\n",
    "print(f\"   - Threshold: {MIN_RATING_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 3: Download e Carregamento do Dataset (com cache)\n",
    "\n",
    "dataset_cache = CACHE_DIR / 'dataset_processed.pkl'\n",
    "\n",
    "if dataset_cache.exists():\n",
    "    print(\"üìÇ Carregando dataset do cache...\")\n",
    "    with open(dataset_cache, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        train_df = data['train']\n",
    "        test_df = data['test']\n",
    "        movies_df = data['movies']\n",
    "else:\n",
    "    print(\"üì• Baixando dataset do HuggingFace (pode demorar ~1-2 min)...\")\n",
    "    dataset = load_dataset(\"ashraq/movielens_ratings\")\n",
    "\n",
    "    train_df = dataset['train'].to_pandas()\n",
    "    test_df = dataset['validation'].to_pandas()\n",
    "\n",
    "    print(\"üîÑ Processando metadados dos filmes...\")\n",
    "    # Agregar informa√ß√µes √∫nicas de filmes\n",
    "    movies_df = train_df.groupby('movie_id').agg({\n",
    "        'title': 'first',\n",
    "        'genres': 'first',\n",
    "        'imdbId': 'first',\n",
    "        'tmdbId': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Criar texto para embeddings\n",
    "    movies_df['text'] = movies_df['title'] + ' ' + \\\n",
    "        movies_df['genres'].str.replace('|', ' ', regex=False)\n",
    "\n",
    "    # Cache\n",
    "    with open(dataset_cache, 'wb') as f:\n",
    "        pickle.dump({'train': train_df, 'test': test_df,\n",
    "                    'movies': movies_df}, f)\n",
    "    print(f\"üíæ Dataset salvo em cache: {dataset_cache}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset carregado!\")\n",
    "print(f\"   - Train: {len(train_df):,} ratings\")\n",
    "print(f\"   - Test: {len(test_df):,} ratings\")\n",
    "print(f\"   - Filmes √∫nicos: {len(movies_df):,}\")\n",
    "print(f\"   - Usu√°rios √∫nicos: {train_df['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [UTILIT√ÅRIO] Limpar Cache para Reprocessamento\n",
    "\n",
    "# IMPORTANTE: Execute esta c√©lula APENAS quando precisar regenerar os arquivos\n",
    "# de cache ap√≥s alterar par√¢metros na C√©lula 2\n",
    "\n",
    "import os\n",
    "\n",
    "def clear_cache_files():\n",
    "    \"\"\"\n",
    "    Remove arquivos de cache que dependem dos par√¢metros configur√°veis.\n",
    "    Use ap√≥s alterar MIN_RATING_THRESHOLD, EMBEDDING_MODEL, TOP_K_SIMILAR, etc.\n",
    "    \"\"\"\n",
    "    files_to_remove = [\n",
    "        'movie_embeddings.pkl',      # Depende de EMBEDDING_MODEL\n",
    "        'item_similarity_topk.pkl',  # Depende de TOP_K_SIMILAR e SIMILARITY_CHUNK_SIZE\n",
    "        'metrics_collaborative.pkl', # Depende de MIN_RATING_THRESHOLD\n",
    "        'metrics_content.pkl',       # Depende de MIN_RATING_THRESHOLD\n",
    "        'metrics_hybrid.pkl'         # Depende de MIN_RATING_THRESHOLD\n",
    "    ]\n",
    "    \n",
    "    removed = []\n",
    "    not_found = []\n",
    "    \n",
    "    for filename in files_to_remove:\n",
    "        filepath = CACHE_DIR / filename\n",
    "        try:\n",
    "            if filepath.exists():\n",
    "                os.remove(filepath)\n",
    "                removed.append(filename)\n",
    "            else:\n",
    "                not_found.append(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao remover {filename}: {e}\")\n",
    "    \n",
    "    print(\"üóëÔ∏è  LIMPEZA DE CACHE COMPLETA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if removed:\n",
    "        print(f\"\\n‚úÖ Arquivos removidos ({len(removed)}):\")\n",
    "        for f in removed:\n",
    "            print(f\"   - {f}\")\n",
    "    \n",
    "    if not_found:\n",
    "        print(f\"\\n‚ÑπÔ∏è  Arquivos j√° n√£o existiam ({len(not_found)}):\")\n",
    "        for f in not_found:\n",
    "            print(f\"   - {f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã PR√ìXIMOS PASSOS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"1. Re-execute a C√©lula 2 para carregar a nova configura√ß√£o\")\n",
    "    print(\"2. Re-execute as c√©lulas afetadas:\")\n",
    "    print(\"   - C√©lula 6: Similaridade item-item (nova com TOP_K=150)\")\n",
    "    print(\"   - C√©lula 8: Embeddings (novo modelo L12-v2)\")\n",
    "    print(\"   - C√©lulas 7, 10, 12: M√©tricas (novo threshold 3.5)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Descomente a linha abaixo para executar a limpeza:\n",
    "# clear_cache_files()\n",
    "\n",
    "print(\"‚ö†Ô∏è  C√©lula de limpeza de cache carregada.\")\n",
    "print(\"Para limpar o cache, descomente a √∫ltima linha e execute esta c√©lula.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 4: An√°lise Explorat√≥ria\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Distribui√ß√£o de Ratings\n",
    "ax = axes[0, 0]\n",
    "train_df['rating'].hist(bins=10, ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_xlabel('Rating')\n",
    "ax.set_ylabel('Frequ√™ncia')\n",
    "ax.set_title('Distribui√ß√£o de Ratings')\n",
    "ax.axvline(MIN_RATING_THRESHOLD, color='red', linestyle='--', label=f'Threshold={MIN_RATING_THRESHOLD}')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Top-20 Filmes Mais Avaliados\n",
    "ax = axes[0, 1]\n",
    "top_movies = train_df['movie_id'].value_counts().head(20)\n",
    "movie_titles = [movies_df[movies_df['movie_id'] == mid]['title'].values[0][:30] for mid in top_movies.index]\n",
    "ax.barh(range(20), top_movies.values, color='coral')\n",
    "ax.set_yticks(range(20))\n",
    "ax.set_yticklabels(movie_titles, fontsize=8)\n",
    "ax.set_xlabel('N¬∫ de Avalia√ß√µes')\n",
    "ax.set_title('Top-20 Filmes Mais Avaliados')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# 3. Distribui√ß√£o de G√™neros\n",
    "ax = axes[1, 0]\n",
    "all_genres = []\n",
    "for genres_str in movies_df['genres'].dropna():\n",
    "    all_genres.extend(genres_str.split('|'))\n",
    "genre_counts = Counter(all_genres).most_common(15)\n",
    "ax.bar([g[0] for g in genre_counts], [g[1] for g in genre_counts], color='mediumseagreen')\n",
    "ax.set_xlabel('G√™nero')\n",
    "ax.set_ylabel('N¬∫ de Filmes')\n",
    "ax.set_title('Top-15 G√™neros')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Sparsidade da Matriz\n",
    "ax = axes[1, 1]\n",
    "n_users = train_df['user_id'].nunique()\n",
    "n_movies = train_df['movie_id'].nunique()\n",
    "n_ratings = len(train_df)\n",
    "sparsity = 1 - (n_ratings / (n_users * n_movies))\n",
    "\n",
    "ax.text(0.5, 0.6, f\"Sparsidade da Matriz\", ha='center', fontsize=16, fontweight='bold')\n",
    "ax.text(0.5, 0.4, f\"{sparsity*100:.2f}%\", ha='center', fontsize=48, color='red')\n",
    "ax.text(0.5, 0.25, f\"{n_users:,} usu√°rios √ó {n_movies:,} filmes\", ha='center', fontsize=12)\n",
    "ax.text(0.5, 0.15, f\"{n_ratings:,} ratings (~{n_ratings/(n_users*n_movies)*100:.3f}% preenchido)\", \n",
    "        ha='center', fontsize=10, style='italic')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'exploratory_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ An√°lise explorat√≥ria salva em: {RESULTS_DIR / 'exploratory_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 2: Abordagem 1 - Filtragem Colaborativa Item-Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 5: Construir Matriz Esparsa Usu√°rio-Item\n",
    "\n",
    "matrix_cache = CACHE_DIR / 'user_item_matrix.pkl'\n",
    "\n",
    "if matrix_cache.exists():\n",
    "    print(\"üìÇ Carregando matriz do cache...\")\n",
    "    with open(matrix_cache, 'rb') as f:\n",
    "        matrix_data = pickle.load(f)\n",
    "        R_train = matrix_data['R_train']\n",
    "        user_to_idx = matrix_data['user_to_idx']\n",
    "        idx_to_user = matrix_data['idx_to_user']\n",
    "        movie_to_idx = matrix_data['movie_to_idx']\n",
    "        idx_to_movie = matrix_data['idx_to_movie']\n",
    "else:\n",
    "    print(\"üîÑ Construindo matriz esparsa usu√°rio-item...\")\n",
    "    \n",
    "    # Criar mapeamentos\n",
    "    unique_users = sorted(train_df['user_id'].unique())\n",
    "    unique_movies = sorted(train_df['movie_id'].unique())\n",
    "    \n",
    "    user_to_idx = {u: i for i, u in enumerate(unique_users)}\n",
    "    idx_to_user = {i: u for u, i in user_to_idx.items()}\n",
    "    movie_to_idx = {m: i for i, m in enumerate(unique_movies)}\n",
    "    idx_to_movie = {i: m for m, i in movie_to_idx.items()}\n",
    "    \n",
    "    # Construir matriz esparsa\n",
    "    rows = train_df['user_id'].map(user_to_idx).values\n",
    "    cols = train_df['movie_id'].map(movie_to_idx).values\n",
    "    data = train_df['rating'].values\n",
    "    \n",
    "    R_train = csr_matrix((data, (rows, cols)), \n",
    "                         shape=(len(unique_users), len(unique_movies)))\n",
    "    \n",
    "    # Cache\n",
    "    with open(matrix_cache, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'R_train': R_train,\n",
    "            'user_to_idx': user_to_idx,\n",
    "            'idx_to_user': idx_to_user,\n",
    "            'movie_to_idx': movie_to_idx,\n",
    "            'idx_to_movie': idx_to_movie\n",
    "        }, f)\n",
    "    print(f\"üíæ Matriz salva em cache: {matrix_cache}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Matriz constru√≠da: {R_train.shape}\")\n",
    "print(f\"   - Mem√≥ria: ~{R_train.data.nbytes / 1024**2:.2f} MB\")\n",
    "print(f\"   - Valores n√£o-nulos: {R_train.nnz:,} ({R_train.nnz / np.prod(R_train.shape) * 100:.3f}% densidade)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 6: Calcular Similaridade Item-Item (Chunked + Top-K Sparse)\n",
    "\n",
    "similarity_cache = CACHE_DIR / 'item_similarity_topk.pkl'\n",
    "\n",
    "if similarity_cache.exists():\n",
    "    print(\"üìÇ Carregando similaridade do cache...\")\n",
    "    with open(similarity_cache, 'rb') as f:\n",
    "        item_similarity_topk = pickle.load(f)\n",
    "else:\n",
    "    print(\"üîÑ Calculando similaridade item-item (chunked, pode demorar ~10-15 min)...\")\n",
    "    \n",
    "    n_movies = R_train.shape[1]\n",
    "    R_items = R_train.T  # Transpor: filmes √ó usu√°rios\n",
    "    \n",
    "    # Guardar apenas top-K similares (economia de mem√≥ria)\n",
    "    item_similarity_topk = {}\n",
    "    \n",
    "    for start_idx in tqdm(range(0, n_movies, SIMILARITY_CHUNK_SIZE), desc=\"Chunks\"):\n",
    "        end_idx = min(start_idx + SIMILARITY_CHUNK_SIZE, n_movies)\n",
    "        chunk = R_items[start_idx:end_idx]\n",
    "        \n",
    "        # Similaridade do chunk com TODOS os filmes\n",
    "        chunk_sim = cosine_similarity(chunk, R_items, dense_output=True)\n",
    "        \n",
    "        # Para cada filme do chunk, guardar top-K\n",
    "        for i, movie_idx in enumerate(range(start_idx, end_idx)):\n",
    "            # Excluir o pr√≥prio filme\n",
    "            sim_scores = chunk_sim[i]\n",
    "            sim_scores[movie_idx] = -1\n",
    "            \n",
    "            # Top-K √≠ndices e scores\n",
    "            top_k_indices = np.argsort(sim_scores)[::-1][:TOP_K_SIMILAR]\n",
    "            top_k_scores = sim_scores[top_k_indices]\n",
    "            \n",
    "            item_similarity_topk[movie_idx] = {\n",
    "                'indices': top_k_indices,\n",
    "                'scores': top_k_scores\n",
    "            }\n",
    "        \n",
    "        # Liberar mem√≥ria\n",
    "        del chunk_sim\n",
    "        gc.collect()\n",
    "    \n",
    "    # Cache\n",
    "    with open(similarity_cache, 'wb') as f:\n",
    "        pickle.dump(item_similarity_topk, f)\n",
    "    print(f\"üíæ Similaridade salva em cache: {similarity_cache}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Similaridade calculada!\")\n",
    "print(f\"   - {len(item_similarity_topk)} filmes √ó top-{TOP_K_SIMILAR} similares\")\n",
    "print(f\"   - Mem√≥ria estimada: ~{len(item_similarity_topk) * TOP_K_SIMILAR * 8 / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 7 OTIMIZADA: Implementar e Avaliar Filtragem Colaborativa\n",
    "# VERS√ÉO R√ÅPIDA: ~5-10 minutos ao inv√©s de 5 horas\n",
    "\n",
    "def recommend_collaborative(user_id, k=10, return_scores=False):\n",
    "    \"\"\"\n",
    "    Recomenda filmes usando filtragem colaborativa item-item\n",
    "    VERS√ÉO OTIMIZADA: N√£o processa filme por filme\n",
    "\n",
    "    Args:\n",
    "        user_id: ID do usu√°rio\n",
    "        k: N√∫mero de recomenda√ß√µes\n",
    "        return_scores: Se True, retorna (movie_ids, scores)\n",
    "\n",
    "    Returns:\n",
    "        list: IDs dos filmes recomendados (ou tuple se return_scores=True)\n",
    "    \"\"\"\n",
    "    if user_id not in user_to_idx:\n",
    "        # Usu√°rio novo: retornar filmes mais populares\n",
    "        top_movies = train_df['movie_id'].value_counts().head(k).index.tolist()\n",
    "        if return_scores:\n",
    "            return top_movies, [1.0] * len(top_movies)\n",
    "        return top_movies\n",
    "\n",
    "    user_idx = user_to_idx[user_id]\n",
    "    user_ratings = R_train[user_idx].toarray().flatten()\n",
    "\n",
    "    # Encontrar quais filmes o usu√°rio avaliou\n",
    "    rated_movie_indices = np.where(user_ratings > 0)[0]\n",
    "\n",
    "    if len(rated_movie_indices) == 0:\n",
    "        # Usu√°rio sem ratings: retornar populares\n",
    "        top_movies = train_df['movie_id'].value_counts().head(k).index.tolist()\n",
    "        if return_scores:\n",
    "            return top_movies, [1.0] * len(top_movies)\n",
    "        return top_movies\n",
    "\n",
    "    # OTIMIZA√á√ÉO: Acumular scores apenas dos filmes similares aos que o usu√°rio avaliou\n",
    "    pred_scores = defaultdict(float)\n",
    "    score_counts = defaultdict(int)\n",
    "\n",
    "    for rated_idx in rated_movie_indices:\n",
    "        user_rating = user_ratings[rated_idx]\n",
    "\n",
    "        # Pegar filmes similares a este que o usu√°rio avaliou\n",
    "        if rated_idx not in item_similarity_topk:\n",
    "            continue\n",
    "\n",
    "        similar_indices = item_similarity_topk[rated_idx]['indices']\n",
    "        similar_scores = item_similarity_topk[rated_idx]['scores']\n",
    "\n",
    "        # Acumular scores ponderados\n",
    "        for sim_idx, sim_score in zip(similar_indices, similar_scores):\n",
    "            # Pular o pr√≥prio filme\n",
    "            if sim_idx == rated_idx:\n",
    "                continue\n",
    "\n",
    "            movie_id = idx_to_movie[sim_idx]\n",
    "            pred_scores[movie_id] += user_rating * sim_score\n",
    "            score_counts[movie_id] += 1\n",
    "\n",
    "    # Normalizar scores pela contagem (m√©dia)\n",
    "    for movie_id in pred_scores:\n",
    "        if score_counts[movie_id] > 0:\n",
    "            pred_scores[movie_id] /= score_counts[movie_id]\n",
    "\n",
    "    # Remover filmes j√° avaliados pelo usu√°rio\n",
    "    for rated_idx in rated_movie_indices:\n",
    "        movie_id = idx_to_movie[rated_idx]\n",
    "        if movie_id in pred_scores:\n",
    "            del pred_scores[movie_id]\n",
    "\n",
    "    # Se n√£o conseguiu gerar recomenda√ß√µes, usar popularidade\n",
    "    if len(pred_scores) == 0:\n",
    "        popular_movies = train_df['movie_id'].value_counts().head(\n",
    "            k).index.tolist()\n",
    "        if return_scores:\n",
    "            return popular_movies, [1.0] * len(popular_movies)\n",
    "        return popular_movies\n",
    "\n",
    "    # Ordenar e pegar top-K\n",
    "    sorted_recs = sorted(pred_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    recommended_movie_ids = [mid for mid, _ in sorted_recs[:k]]\n",
    "\n",
    "    if return_scores:\n",
    "        scores = [pred_scores[mid] for mid in recommended_movie_ids]\n",
    "        return recommended_movie_ids, scores\n",
    "    return recommended_movie_ids\n",
    "\n",
    "\n",
    "# === AVALIA√á√ÉO NO TEST SET ===\n",
    "print(\"üîÑ Avaliando filtragem colaborativa no test set (pode demorar ~5-10 min)...\\n\")\n",
    "\n",
    "test_users = test_df['user_id'].unique()\n",
    "precisions, recalls, ndcgs = [], [], []\n",
    "skipped_no_relevant = 0\n",
    "skipped_not_in_train = 0\n",
    "\n",
    "for user_id in tqdm(test_users[:1000], desc=\"Avaliando\"):\n",
    "    # Verificar se usu√°rio est√° no train\n",
    "    if user_id not in user_to_idx:\n",
    "        skipped_not_in_train += 1\n",
    "        continue\n",
    "\n",
    "    # Ground truth: filmes que o usu√°rio gostou no TEST\n",
    "    user_test = test_df[test_df['user_id'] == user_id]\n",
    "    relevant_items = set(\n",
    "        user_test[user_test['rating'] >= MIN_RATING_THRESHOLD]['movie_id'].values)\n",
    "\n",
    "    if len(relevant_items) == 0:\n",
    "        skipped_no_relevant += 1\n",
    "        continue\n",
    "\n",
    "    # Gerar recomenda√ß√µes\n",
    "    try:\n",
    "        recs = recommend_collaborative(user_id, k=K)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no usu√°rio {user_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Precision@K\n",
    "    hits = len(set(recs) & relevant_items)\n",
    "    precision = hits / K\n",
    "    precisions.append(precision)\n",
    "\n",
    "    # Recall@K\n",
    "    recall = hits / len(relevant_items)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    # NDCG@K\n",
    "    relevance = [1 if mid in relevant_items else 0 for mid in recs]\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    if sum(ideal_relevance) > 0:\n",
    "        ndcg = ndcg_score([ideal_relevance], [relevance])\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "print(f\"\\nüìä Filtragem Colaborativa - M√©tricas:\")\n",
    "print(\n",
    "    f\"   - Precision@{K}: {np.mean(precisions):.3f} ¬± {np.std(precisions):.3f}\")\n",
    "print(f\"   - Recall@{K}: {np.mean(recalls):.3f} ¬± {np.std(recalls):.3f}\")\n",
    "print(f\"   - NDCG@{K}: {np.mean(ndcgs):.3f} ¬± {np.std(ndcgs):.3f}\")\n",
    "print(f\"\\n   ‚ÑπÔ∏è  Usu√°rios avaliados: {len(precisions)}\")\n",
    "print(f\"   ‚ö†Ô∏è  Pulados (n√£o no train): {skipped_not_in_train}\")\n",
    "print(f\"   ‚ö†Ô∏è  Pulados (sem relevantes): {skipped_no_relevant}\")\n",
    "\n",
    "# Salvar m√©tricas\n",
    "metrics_collaborative = {\n",
    "    'precision': (np.mean(precisions), np.std(precisions)),\n",
    "    'recall': (np.mean(recalls), np.std(recalls)),\n",
    "    'ndcg': (np.mean(ndcgs), np.std(ndcgs))\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR / 'metrics_collaborative.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_collaborative, f)\n",
    "\n",
    "print(f\"\\n‚úÖ M√©tricas salvas em: {CACHE_DIR / 'metrics_collaborative.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 3: Abordagem 2 - Filtragem Baseada em Conte√∫do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 8: Gerar Embeddings de Filmes (Mini-batches)\n",
    "\n",
    "embeddings_cache = CACHE_DIR / 'movie_embeddings.pkl'\n",
    "\n",
    "if embeddings_cache.exists():\n",
    "    print(\"üìÇ Carregando embeddings do cache...\")\n",
    "    with open(embeddings_cache, 'rb') as f:\n",
    "        movie_embeddings = pickle.load(f)\n",
    "else:\n",
    "    print(f\"üîÑ Gerando embeddings com {EMBEDDING_MODEL} (pode demorar ~15-20 min)...\")\n",
    "    \n",
    "    model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "    \n",
    "    # Processar em mini-batches (economia de RAM)\n",
    "    all_embeddings = []\n",
    "    texts = movies_df['text'].tolist()\n",
    "    \n",
    "    for start_idx in tqdm(range(0, len(texts), EMBEDDING_BATCH_SIZE), desc=\"Batches\"):\n",
    "        end_idx = min(start_idx + EMBEDDING_BATCH_SIZE, len(texts))\n",
    "        batch_texts = texts[start_idx:end_idx]\n",
    "        \n",
    "        batch_emb = model.encode(batch_texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "        all_embeddings.append(batch_emb)\n",
    "        \n",
    "        # Liberar mem√≥ria a cada 1000 filmes\n",
    "        if (start_idx + EMBEDDING_BATCH_SIZE) % 1000 == 0:\n",
    "            gc.collect()\n",
    "    \n",
    "    movie_embeddings = np.vstack(all_embeddings)\n",
    "    \n",
    "    # Cache\n",
    "    with open(embeddings_cache, 'wb') as f:\n",
    "        pickle.dump(movie_embeddings, f)\n",
    "    print(f\"üíæ Embeddings salvos em cache: {embeddings_cache}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Embeddings gerados: {movie_embeddings.shape}\")\n",
    "print(f\"   - Mem√≥ria: ~{movie_embeddings.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "# Criar mapeamento movie_id ‚Üí embedding index\n",
    "movie_id_to_emb_idx = {row['movie_id']: idx for idx, row in movies_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 9: Construir Perfis de Usu√°rios e Implementar Recomenda√ß√£o\n",
    "\n",
    "def build_user_profile_content(user_ratings_dict):\n",
    "    \"\"\"\n",
    "    Constr√≥i perfil do usu√°rio como m√©dia ponderada dos embeddings\n",
    "    \n",
    "    Args:\n",
    "        user_ratings_dict: {movie_id: rating}\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Perfil do usu√°rio (embedding m√©dio ponderado)\n",
    "    \"\"\"\n",
    "    weighted_embeddings = []\n",
    "    \n",
    "    for movie_id, rating in user_ratings_dict.items():\n",
    "        if movie_id in movie_id_to_emb_idx:\n",
    "            emb_idx = movie_id_to_emb_idx[movie_id]\n",
    "            weighted_embeddings.append(rating * movie_embeddings[emb_idx])\n",
    "    \n",
    "    if len(weighted_embeddings) == 0:\n",
    "        # Retornar embedding m√©dio de todos os filmes\n",
    "        return np.mean(movie_embeddings, axis=0)\n",
    "    \n",
    "    return np.mean(weighted_embeddings, axis=0)\n",
    "\n",
    "\n",
    "def recommend_content(user_id, k=10, return_scores=False):\n",
    "    \"\"\"\n",
    "    Recomenda filmes usando filtragem baseada em conte√∫do\n",
    "    \n",
    "    Args:\n",
    "        user_id: ID do usu√°rio\n",
    "        k: N√∫mero de recomenda√ß√µes\n",
    "        return_scores: Se True, retorna (movie_ids, scores)\n",
    "    \n",
    "    Returns:\n",
    "        list: IDs dos filmes recomendados (ou tuple se return_scores=True)\n",
    "    \"\"\"\n",
    "    # Obter ratings do usu√°rio\n",
    "    user_data = train_df[train_df['user_id'] == user_id]\n",
    "    \n",
    "    if len(user_data) == 0:\n",
    "        # Usu√°rio novo: retornar filmes populares de g√™neros diversos\n",
    "        top_movies = train_df['movie_id'].value_counts().head(k).index.tolist()\n",
    "        if return_scores:\n",
    "            return top_movies, [1.0] * len(top_movies)\n",
    "        return top_movies\n",
    "    \n",
    "    user_ratings_dict = dict(zip(user_data['movie_id'], user_data['rating']))\n",
    "    \n",
    "    # Construir perfil\n",
    "    user_profile = build_user_profile_content(user_ratings_dict)\n",
    "    \n",
    "    # Calcular similaridade com todos os filmes\n",
    "    similarities = cosine_similarity([user_profile], movie_embeddings)[0]\n",
    "    \n",
    "    # Remover filmes j√° avaliados\n",
    "    for movie_id in user_ratings_dict.keys():\n",
    "        if movie_id in movie_id_to_emb_idx:\n",
    "            emb_idx = movie_id_to_emb_idx[movie_id]\n",
    "            similarities[emb_idx] = -np.inf\n",
    "    \n",
    "    # Top-K recomenda√ß√µes\n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "    recommended_movie_ids = [movies_df.iloc[idx]['movie_id'] for idx in top_k_indices]\n",
    "    \n",
    "    if return_scores:\n",
    "        return recommended_movie_ids, similarities[top_k_indices]\n",
    "    return recommended_movie_ids\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de recomenda√ß√£o baseada em conte√∫do definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 10 OTIMIZADA: Avaliar Filtragem Baseada em Conte√∫do\n",
    "\n",
    "print(\"üîÑ Avaliando filtragem baseada em conte√∫do no test set...\\n\")\n",
    "\n",
    "precisions_content, recalls_content, ndcgs_content = [], [], []\n",
    "skipped_no_relevant = 0\n",
    "skipped_not_in_train = 0\n",
    "\n",
    "for user_id in tqdm(test_users[:1000], desc=\"Avaliando\"):\n",
    "    # Verificar se usu√°rio est√° no train\n",
    "    user_data = train_df[train_df['user_id'] == user_id]\n",
    "    if len(user_data) == 0:\n",
    "        skipped_not_in_train += 1\n",
    "        continue\n",
    "\n",
    "    # Ground truth: filmes que o usu√°rio gostou no TEST\n",
    "    user_test = test_df[test_df['user_id'] == user_id]\n",
    "    relevant_items = set(\n",
    "        user_test[user_test['rating'] >= MIN_RATING_THRESHOLD]['movie_id'].values)\n",
    "\n",
    "    if len(relevant_items) == 0:\n",
    "        skipped_no_relevant += 1\n",
    "        continue\n",
    "\n",
    "    # Recomendar\n",
    "    try:\n",
    "        recs = recommend_content(user_id, k=K)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no usu√°rio {user_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # M√©tricas\n",
    "    hits = len(set(recs) & relevant_items)\n",
    "    precision = hits / K\n",
    "    precisions_content.append(precision)\n",
    "\n",
    "    recall = hits / len(relevant_items)\n",
    "    recalls_content.append(recall)\n",
    "\n",
    "    relevance = [1 if mid in relevant_items else 0 for mid in recs]\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    if sum(ideal_relevance) > 0:\n",
    "        ndcg = ndcg_score([ideal_relevance], [relevance])\n",
    "        ndcgs_content.append(ndcg)\n",
    "\n",
    "print(f\"\\nüìä Filtragem Baseada em Conte√∫do - M√©tricas:\")\n",
    "print(\n",
    "    f\"   - Precision@{K}: {np.mean(precisions_content):.3f} ¬± {np.std(precisions_content):.3f}\")\n",
    "print(\n",
    "    f\"   - Recall@{K}: {np.mean(recalls_content):.3f} ¬± {np.std(recalls_content):.3f}\")\n",
    "print(\n",
    "    f\"   - NDCG@{K}: {np.mean(ndcgs_content):.3f} ¬± {np.std(ndcgs_content):.3f}\")\n",
    "print(f\"\\n   ‚ÑπÔ∏è  Usu√°rios avaliados: {len(precisions_content)}\")\n",
    "print(f\"   ‚ö†Ô∏è  Pulados (n√£o no train): {skipped_not_in_train}\")\n",
    "print(f\"   ‚ö†Ô∏è  Pulados (sem relevantes): {skipped_no_relevant}\")\n",
    "\n",
    "# Salvar m√©tricas\n",
    "metrics_content = {\n",
    "    'precision': (np.mean(precisions_content), np.std(precisions_content)),\n",
    "    'recall': (np.mean(recalls_content), np.std(recalls_content)),\n",
    "    'ndcg': (np.mean(ndcgs_content), np.std(ndcgs_content))\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR / 'metrics_content.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_content, f)\n",
    "\n",
    "print(f\"\\n‚úÖ M√©tricas salvas em: {CACHE_DIR / 'metrics_content.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 4: Abordagem 3 - Sistema H√≠brido Adaptativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 11: Implementar Sistema H√≠brido com Œ± Adaptativo\n",
    "\n",
    "def calculate_adaptive_alpha(user_id):\n",
    "    \"\"\"\n",
    "    Calcula Œ± adaptativo baseado no n√∫mero de ratings do usu√°rio\n",
    "\n",
    "    Œ± = min(0.9, 0.3 + 0.6 * (num_ratings / ALPHA_MAX_RATINGS))\n",
    "\n",
    "    - Novo (< 5 ratings): Œ± ‚âà 0.3-0.4 ‚Üí favorece conte√∫do\n",
    "    - Casual (10-20 ratings): Œ± ‚âà 0.4-0.5 ‚Üí balanceado\n",
    "    - Ativo (50+ ratings): Œ± ‚âà 0.9 ‚Üí favorece colaborativo\n",
    "    \"\"\"\n",
    "    user_data = train_df[train_df['user_id'] == user_id]\n",
    "    num_ratings = len(user_data)\n",
    "\n",
    "    if num_ratings < ALPHA_MIN_RATINGS:\n",
    "        return 0.3  # Muito novo, confia s√≥ no conte√∫do\n",
    "\n",
    "    alpha = 0.3 + 0.6 * (num_ratings / ALPHA_MAX_RATINGS)\n",
    "    return min(0.9, alpha)\n",
    "\n",
    "\n",
    "def recommend_hybrid(user_id, k=10, alpha='adaptive', return_scores=False):\n",
    "    \"\"\"\n",
    "    Recomenda filmes usando sistema h√≠brido\n",
    "\n",
    "    Args:\n",
    "        user_id: ID do usu√°rio\n",
    "        k: N√∫mero de recomenda√ß√µes\n",
    "        alpha: float ou 'adaptive' (padr√£o)\n",
    "        return_scores: Se True, retorna (movie_ids, scores)\n",
    "\n",
    "    Returns:\n",
    "        list: IDs dos filmes recomendados (ou tuple se return_scores=True)\n",
    "    \"\"\"\n",
    "    # Determinar Œ±\n",
    "    if alpha == 'adaptive':\n",
    "        alpha_value = calculate_adaptive_alpha(user_id)\n",
    "    else:\n",
    "        alpha_value = float(alpha)\n",
    "\n",
    "    # Obter recomenda√ß√µes das duas abordagens\n",
    "    recs_colab, scores_colab = recommend_collaborative(\n",
    "        user_id, k=50, return_scores=True)\n",
    "    recs_content, scores_content = recommend_content(\n",
    "        user_id, k=50, return_scores=True)\n",
    "\n",
    "    # Criar dicion√°rio unificado de scores\n",
    "    all_movie_ids = set(recs_colab) | set(recs_content)\n",
    "    combined_scores = {}\n",
    "\n",
    "    # Normalizar scores para [0, 1]\n",
    "    scores_colab_array = np.array(scores_colab)\n",
    "    scores_content_array = np.array(scores_content)\n",
    "\n",
    "    if scores_colab_array.max() > scores_colab_array.min():\n",
    "        scores_colab_norm = (scores_colab_array - scores_colab_array.min()) / \\\n",
    "            (scores_colab_array.max() - scores_colab_array.min())\n",
    "    else:\n",
    "        scores_colab_norm = np.ones_like(scores_colab_array)\n",
    "\n",
    "    if scores_content_array.max() > scores_content_array.min():\n",
    "        scores_content_norm = (scores_content_array - scores_content_array.min()) / \\\n",
    "            (scores_content_array.max() - scores_content_array.min())\n",
    "    else:\n",
    "        scores_content_norm = np.ones_like(scores_content_array)\n",
    "\n",
    "    # Mapear scores normalizados\n",
    "    colab_dict = {mid: score for mid, score in zip(\n",
    "        recs_colab, scores_colab_norm)}\n",
    "    content_dict = {mid: score for mid, score in zip(\n",
    "        recs_content, scores_content_norm)}\n",
    "\n",
    "    # Combinar scores\n",
    "    for movie_id in all_movie_ids:\n",
    "        score_c = colab_dict.get(movie_id, 0)\n",
    "        score_ct = content_dict.get(movie_id, 0)\n",
    "        combined_scores[movie_id] = alpha_value * \\\n",
    "            score_c + (1 - alpha_value) * score_ct\n",
    "\n",
    "    # Top-K\n",
    "    sorted_movies = sorted(combined_scores.items(),\n",
    "                        key=lambda x: x[1], reverse=True)\n",
    "    recommended_movie_ids = [mid for mid, _ in sorted_movies[:k]]\n",
    "\n",
    "    if return_scores:\n",
    "        scores = [combined_scores[mid] for mid in recommended_movie_ids]\n",
    "        return recommended_movie_ids, scores\n",
    "    return recommended_movie_ids\n",
    "\n",
    "\n",
    "print(\"‚úÖ Sistema h√≠brido implementado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 12 OTIMIZADA: Avaliar Sistema H√≠brido\n",
    "\n",
    "print(\"üîÑ Avaliando sistema h√≠brido no test set...\\n\")\n",
    "\n",
    "precisions_hybrid, recalls_hybrid, ndcgs_hybrid = [], [], []\n",
    "skipped_no_relevant = 0\n",
    "skipped_not_in_train = 0\n",
    "\n",
    "for user_id in tqdm(test_users[:1000], desc=\"Avaliando\"):\n",
    "    # Verificar se usu√°rio est√° no train\n",
    "    if user_id not in user_to_idx:\n",
    "        skipped_not_in_train += 1\n",
    "        continue\n",
    "\n",
    "    # Ground truth: filmes que o usu√°rio gostou no TEST\n",
    "    user_test = test_df[test_df['user_id'] == user_id]\n",
    "    relevant_items = set(\n",
    "        user_test[user_test['rating'] >= MIN_RATING_THRESHOLD]['movie_id'].values)\n",
    "\n",
    "    if len(relevant_items) == 0:\n",
    "        skipped_no_relevant += 1\n",
    "        continue\n",
    "\n",
    "    # Recomendar com sistema h√≠brido adaptativo\n",
    "    try:\n",
    "        recs = recommend_hybrid(user_id, k=K, alpha='adaptive')\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no usu√°rio {user_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    hits = len(set(recs) & relevant_items)\n",
    "    precision = hits / K\n",
    "    precisions_hybrid.append(precision)\n",
    "\n",
    "    recall = hits / len(relevant_items)\n",
    "    recalls_hybrid.append(recall)\n",
    "\n",
    "    relevance = [1 if mid in relevant_items else 0 for mid in recs]\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    if sum(ideal_relevance) > 0:\n",
    "        ndcg = ndcg_score([ideal_relevance], [relevance])\n",
    "        ndcgs_hybrid.append(ndcg)\n",
    "\n",
    "print(f\"\\nüìä Sistema H√≠brido - M√©tricas:\")\n",
    "print(\n",
    "    f\"   - Precision@{K}: {np.mean(precisions_hybrid):.3f} ¬± {np.std(precisions_hybrid):.3f}\")\n",
    "print(\n",
    "    f\"   - Recall@{K}: {np.mean(recalls_hybrid):.3f} ¬± {np.std(recalls_hybrid):.3f}\")\n",
    "print(\n",
    "    f\"   - NDCG@{K}: {np.mean(ndcgs_hybrid):.3f} ¬± {np.std(ndcgs_hybrid):.3f}\")\n",
    "print(f\"\\n   ‚ÑπÔ∏è  Usu√°rios avaliados: {len(precisions_hybrid)}\")\n",
    "print(f\"   ‚ö†Ô∏è  Pulados (n√£o no train): {skipped_not_in_train}\")\n",
    "print(f\"   ‚ö†Ô∏è  Pulados (sem relevantes): {skipped_no_relevant}\")\n",
    "\n",
    "metrics_hybrid = {\n",
    "    'precision': (np.mean(precisions_hybrid), np.std(precisions_hybrid)),\n",
    "    'recall': (np.mean(recalls_hybrid), np.std(recalls_hybrid)),\n",
    "    'ndcg': (np.mean(ndcgs_hybrid), np.std(ndcgs_hybrid))\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR / 'metrics_hybrid.pkl', 'wb') as f:\n",
    "    pickle.dump(metrics_hybrid, f)\n",
    "\n",
    "print(f\"\\n‚úÖ M√©tricas salvas em: {CACHE_DIR / 'metrics_hybrid.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 13: An√°lise de Cold-Start (Performance vs N¬∫ de Ratings)\n",
    "\n",
    "print(\"üîÑ Analisando performance em diferentes n√≠veis de experi√™ncia do usu√°rio...\\n\")\n",
    "\n",
    "# Agrupar usu√°rios por n√∫mero de ratings\n",
    "rating_buckets = {\n",
    "    '1-5': (1, 5),\n",
    "    '6-10': (6, 10),\n",
    "    '11-20': (11, 20),\n",
    "    '21-50': (21, 50),\n",
    "    '50+': (51, np.inf)\n",
    "}\n",
    "\n",
    "results_by_bucket = {\n",
    "    'Colaborativo': defaultdict(list),\n",
    "    'Conte√∫do': defaultdict(list),\n",
    "    'H√≠brido': defaultdict(list)\n",
    "}\n",
    "\n",
    "for user_id in tqdm(test_users[:500], desc=\"An√°lise Cold-Start\"):  # Amostra menor\n",
    "    user_test = test_df[test_df['user_id'] == user_id]\n",
    "    relevant_items = set(\n",
    "        user_test[user_test['rating'] >= MIN_RATING_THRESHOLD]['movie_id'].values)\n",
    "\n",
    "    if len(relevant_items) == 0:\n",
    "        continue\n",
    "\n",
    "    # Determinar bucket\n",
    "    num_ratings = len(train_df[train_df['user_id'] == user_id])\n",
    "    bucket_name = None\n",
    "    for name, (min_r, max_r) in rating_buckets.items():\n",
    "        if min_r <= num_ratings <= max_r:\n",
    "            bucket_name = name\n",
    "            break\n",
    "\n",
    "    if bucket_name is None:\n",
    "        continue\n",
    "\n",
    "    # Avaliar 3 m√©todos\n",
    "    for method_name, method_func in [\n",
    "        ('Colaborativo', recommend_collaborative),\n",
    "        ('Conte√∫do', recommend_content),\n",
    "        ('H√≠brido', recommend_hybrid)\n",
    "    ]:\n",
    "        recs = method_func(user_id, k=K)\n",
    "        hits = len(set(recs) & relevant_items)\n",
    "        precision = hits / K\n",
    "        results_by_bucket[method_name][bucket_name].append(precision)\n",
    "\n",
    "# Calcular m√©dias\n",
    "avg_results = {method: {} for method in results_by_bucket.keys()}\n",
    "for method in results_by_bucket:\n",
    "    for bucket in rating_buckets.keys():\n",
    "        if bucket in results_by_bucket[method] and len(results_by_bucket[method][bucket]) > 0:\n",
    "            avg_results[method][bucket] = np.mean(\n",
    "                results_by_bucket[method][bucket])\n",
    "        else:\n",
    "            avg_results[method][bucket] = 0\n",
    "\n",
    "# Visualizar\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x_pos = np.arange(len(rating_buckets))\n",
    "width = 0.25\n",
    "\n",
    "for i, (method, color) in enumerate([\n",
    "    ('Colaborativo', 'steelblue'),\n",
    "    ('Conte√∫do', 'coral'),\n",
    "    ('H√≠brido', 'mediumseagreen')\n",
    "]):\n",
    "    values = [avg_results[method][bucket] for bucket in rating_buckets.keys()]\n",
    "    ax.bar(x_pos + i*width, values, width,\n",
    "        label=method, color=color, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('N¬∫ de Ratings do Usu√°rio', fontsize=12)\n",
    "ax.set_ylabel(f'Precision@{K}', fontsize=12)\n",
    "ax.set_title('An√°lise de Cold-Start: Performance vs Experi√™ncia do Usu√°rio',\n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x_pos + width)\n",
    "ax.set_xticklabels(rating_buckets.keys())\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'cold_start_analysis.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"\\n‚úÖ An√°lise de cold-start salva em: {RESULTS_DIR / 'cold_start_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 5: Visualiza√ß√µes Comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 14: T-SNE - Visualiza√ß√£o de Embeddings por G√™nero\n",
    "\n",
    "print(\"üîÑ Aplicando T-SNE nos embeddings (pode demorar ~3-5 min)...\\n\")\n",
    "\n",
    "tsne_cache = CACHE_DIR / 'tsne_2d.pkl'\n",
    "\n",
    "if tsne_cache.exists():\n",
    "    print(\"üìÇ Carregando T-SNE do cache...\")\n",
    "    with open(tsne_cache, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        embeddings_2d = data['embeddings_2d']\n",
    "        sample_indices = data['sample_indices']\n",
    "else:\n",
    "    # Usar amostra para velocidade (1000 filmes)\n",
    "    sample_size = min(1000, len(movie_embeddings))\n",
    "    sample_indices = np.random.choice(\n",
    "        len(movie_embeddings), sample_size, replace=False)\n",
    "\n",
    "    # CORRE√á√ÉO: n_iter ‚Üí max_iter (sklearn >= 1.0)\n",
    "    tsne = TSNE(n_components=2, perplexity=30, max_iter=1000,\n",
    "                random_state=RANDOM_STATE, verbose=1)\n",
    "    embeddings_2d = tsne.fit_transform(movie_embeddings[sample_indices])\n",
    "\n",
    "    with open(tsne_cache, 'wb') as f:\n",
    "        pickle.dump({'embeddings_2d': embeddings_2d,\n",
    "                    'sample_indices': sample_indices}, f)\n",
    "    print(f\"üíæ T-SNE salvo em cache: {tsne_cache}\")\n",
    "\n",
    "# Extrair g√™nero principal de cada filme\n",
    "sample_movies = movies_df.iloc[sample_indices]\n",
    "primary_genres = sample_movies['genres'].str.split('|').str[0]\n",
    "\n",
    "# Top-5 g√™neros mais comuns\n",
    "top_genres = primary_genres.value_counts().head(5).index.tolist()\n",
    "genre_colors = {\n",
    "    'Drama': '#FF6B6B',\n",
    "    'Comedy': '#4ECDC4',\n",
    "    'Action': '#45B7D1',\n",
    "    'Thriller': '#FFA07A',\n",
    "    'Romance': '#DDA0DD',\n",
    "    'Sci-Fi': '#98D8C8',\n",
    "    'Horror': '#F7DC6F'\n",
    "}\n",
    "\n",
    "# Visualizar\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "for genre in top_genres:\n",
    "    mask = primary_genres == genre\n",
    "    color = genre_colors.get(genre, '#CCCCCC')\n",
    "    ax.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],\n",
    "            c=color, label=genre, alpha=0.6, s=50, edgecolors='black', linewidth=0.3)\n",
    "\n",
    "# Outros g√™neros em cinza\n",
    "mask_others = ~primary_genres.isin(top_genres)\n",
    "ax.scatter(embeddings_2d[mask_others, 0], embeddings_2d[mask_others, 1],\n",
    "        c='#CCCCCC', label='Outros', alpha=0.3, s=30)\n",
    "\n",
    "ax.set_title('T-SNE: Embeddings de Filmes Agrupados por G√™nero',\n",
    "            fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Dimens√£o 1', fontsize=12)\n",
    "ax.set_ylabel('Dimens√£o 2', fontsize=12)\n",
    "ax.legend(fontsize=10, loc='best')\n",
    "ax.grid(True, alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'tsne_movies_by_genre.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ T-SNE salvo em: {RESULTS_DIR / 'tsne_movies_by_genre.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 15: Compara√ß√£o Gr√°fica das 3 Abordagens\n",
    "\n",
    "# Carregar m√©tricas\n",
    "with open(CACHE_DIR / 'metrics_collaborative.pkl', 'rb') as f:\n",
    "    metrics_collaborative = pickle.load(f)\n",
    "with open(CACHE_DIR / 'metrics_content.pkl', 'rb') as f:\n",
    "    metrics_content = pickle.load(f)\n",
    "with open(CACHE_DIR / 'metrics_hybrid.pkl', 'rb') as f:\n",
    "    metrics_hybrid = pickle.load(f)\n",
    "\n",
    "# Preparar dados\n",
    "methods = ['Colaborativo', 'Conte√∫do', 'H√≠brido']\n",
    "precision_means = [\n",
    "    metrics_collaborative['precision'][0],\n",
    "    metrics_content['precision'][0],\n",
    "    metrics_hybrid['precision'][0]\n",
    "]\n",
    "recall_means = [\n",
    "    metrics_collaborative['recall'][0],\n",
    "    metrics_content['recall'][0],\n",
    "    metrics_hybrid['recall'][0]\n",
    "]\n",
    "ndcg_means = [\n",
    "    metrics_collaborative['ndcg'][0],\n",
    "    metrics_content['ndcg'][0],\n",
    "    metrics_hybrid['ndcg'][0]\n",
    "]\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen']\n",
    "\n",
    "# Precision@10\n",
    "ax = axes[0]\n",
    "bars = ax.bar(methods, precision_means, color=colors,\n",
    "            alpha=0.8, edgecolor='black')\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title(f'Precision@{K}', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(precision_means) * 1.2)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, (bar, val) in enumerate(zip(bars, precision_means)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.01, f'{val:.3f}',\n",
    "            ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Recall@10\n",
    "ax = axes[1]\n",
    "bars = ax.bar(methods, recall_means, color=colors,\n",
    "            alpha=0.8, edgecolor='black')\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title(f'Recall@{K}', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(recall_means) * 1.2)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, (bar, val) in enumerate(zip(bars, recall_means)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.01, f'{val:.3f}',\n",
    "            ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# NDCG@10\n",
    "ax = axes[2]\n",
    "bars = ax.bar(methods, ndcg_means, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title(f'NDCG@{K}', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(ndcg_means) * 1.2)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, (bar, val) in enumerate(zip(bars, ndcg_means)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.01, f'{val:.3f}',\n",
    "            ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Compara√ß√£o de Performance: 3 Abordagens de Recomenda√ß√£o',\n",
    "            fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'metrics_comparison.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Compara√ß√£o salva em: {RESULTS_DIR / 'metrics_comparison.png'}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMO DAS M√âTRICAS:\")\n",
    "print(\"=\"*60)\n",
    "for method, p, r, n in zip(methods, precision_means, recall_means, ndcg_means):\n",
    "    print(f\"{method:15} | Precision: {p:.3f} | Recall: {r:.3f} | NDCG: {n:.3f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTE 2: Sistema Interativo com Jupyter Widgets\n",
    "\n",
    "### Interface de Recomenda√ß√£o Personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 16: Interface de Sele√ß√£o de Filmes\n",
    "\n",
    "# Preparar lista de t√≠tulos de filmes para autocomplete\n",
    "all_movie_titles = sorted(movies_df['title'].unique().tolist())\n",
    "movie_title_to_id = dict(zip(movies_df['title'], movies_df['movie_id']))\n",
    "\n",
    "# Estado global para armazenar sele√ß√µes do usu√°rio\n",
    "user_selection_state = {'movies': {}}\n",
    "\n",
    "print(\"üé¨ SISTEMA INTERATIVO DE RECOMENDA√á√ÉO DE FILMES\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìù Instru√ß√µes:\")\n",
    "print(\"1. Selecione 5-10 filmes que voc√™ j√° assistiu\")\n",
    "print(\"2. D√™ uma nota de 1-5 estrelas para cada filme\")\n",
    "print(\"3. Use os controles abaixo para personalizar as recomenda√ß√µes\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Criar widgets de sele√ß√£o de filmes\n",
    "movie_widgets = []\n",
    "\n",
    "for i in range(10):\n",
    "    # Dropdown para selecionar filme\n",
    "    movie_dropdown = widgets.Dropdown(\n",
    "        options=[''] + all_movie_titles,\n",
    "        value='',\n",
    "        description=f'Filme {i+1}:',\n",
    "        layout=widgets.Layout(width='500px'),\n",
    "        style={'description_width': '70px'}\n",
    "    )\n",
    "\n",
    "    # Slider para nota\n",
    "    rating_slider = widgets.IntSlider(\n",
    "        value=4,\n",
    "        min=1,\n",
    "        max=5,\n",
    "        step=1,\n",
    "        description='Nota:',\n",
    "        layout=widgets.Layout(width='300px'),\n",
    "        style={'description_width': '50px'},\n",
    "        disabled=True  # Desabilitado at√© selecionar filme\n",
    "    )\n",
    "\n",
    "    # Callback para habilitar/desabilitar slider\n",
    "    def make_on_change_callback(slider, idx):\n",
    "        def on_change(change):\n",
    "            if change['new'] != '':\n",
    "                slider.disabled = False\n",
    "                # Salvar no estado\n",
    "                movie_id = movie_title_to_id[change['new']]\n",
    "                user_selection_state['movies'][idx] = {\n",
    "                    'title': change['new'],\n",
    "                    'movie_id': movie_id,\n",
    "                    'rating': slider.value\n",
    "                }\n",
    "            else:\n",
    "                slider.disabled = True\n",
    "                if idx in user_selection_state['movies']:\n",
    "                    del user_selection_state['movies'][idx]\n",
    "        return on_change\n",
    "\n",
    "    def make_rating_callback(dropdown, idx):\n",
    "        def on_rating_change(change):\n",
    "            if idx in user_selection_state['movies']:\n",
    "                user_selection_state['movies'][idx]['rating'] = change['new']\n",
    "        return on_rating_change\n",
    "\n",
    "    movie_dropdown.observe(make_on_change_callback(\n",
    "        rating_slider, i), names='value')\n",
    "    rating_slider.observe(make_rating_callback(\n",
    "        movie_dropdown, i), names='value')\n",
    "\n",
    "    movie_widgets.append(widgets.HBox([movie_dropdown, rating_slider]))\n",
    "\n",
    "# Layout vertical com todos os seletores\n",
    "movie_selection_box = widgets.VBox(\n",
    "    movie_widgets,\n",
    "    layout=widgets.Layout(border='2px solid #ccc',\n",
    "                        padding='10px', margin='10px')\n",
    ")\n",
    "\n",
    "display(widgets.HTML(\"<h3>üìΩÔ∏è Selecione os Filmes que Voc√™ J√° Assistiu:</h3>\"))\n",
    "display(movie_selection_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 17: Controles do Sistema de Recomenda√ß√£o\n",
    "\n",
    "# M√©todo de recomenda√ß√£o\n",
    "method_selector = widgets.RadioButtons(\n",
    "    options=['Colaborativo', 'Conte√∫do', 'H√≠brido'],\n",
    "    value='H√≠brido',\n",
    "    description='M√©todo:',\n",
    "    style={'description_width': '80px'}\n",
    ")\n",
    "\n",
    "# Slider para Œ± (apenas para h√≠brido)\n",
    "alpha_slider = widgets.FloatSlider(\n",
    "    value=0.7,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Œ± (Colab):',\n",
    "    readout_format='.2f',\n",
    "    style={'description_width': '80px'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "alpha_label = widgets.HTML(\n",
    "    value=\"<i>Œ± = 0: s√≥ conte√∫do | Œ± = 1: s√≥ colaborativo | Œ± = adaptativo (recomendado)</i>\"\n",
    ")\n",
    "\n",
    "# Checkbox para usar Œ± adaptativo\n",
    "adaptive_alpha_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Usar Œ± adaptativo',\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "\n",
    "def on_adaptive_change(change):\n",
    "    alpha_slider.disabled = change['new']\n",
    "\n",
    "\n",
    "adaptive_alpha_checkbox.observe(on_adaptive_change, names='value')\n",
    "alpha_slider.disabled = True  # Inicialmente desabilitado\n",
    "\n",
    "# Slider para n√∫mero de recomenda√ß√µes\n",
    "k_slider = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=5,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Top-K:',\n",
    "    style={'description_width': '80px'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Organizar controles\n",
    "controls_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>‚öôÔ∏è Configura√ß√µes de Recomenda√ß√£o:</h3>\"),\n",
    "    method_selector,\n",
    "    widgets.HTML(\"<br><b>Par√¢metros do H√≠brido:</b>\"),\n",
    "    adaptive_alpha_checkbox,\n",
    "    alpha_slider,\n",
    "    alpha_label,\n",
    "    widgets.HTML(\"<br><b>N√∫mero de Recomenda√ß√µes:</b>\"),\n",
    "    k_slider\n",
    "], layout=widgets.Layout(border='2px solid #ccc', padding='10px', margin='10px'))\n",
    "\n",
    "display(controls_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 18: Gera√ß√£o de Recomenda√ß√µes Interativa\n",
    "\n",
    "# Fun√ß√µes auxiliares para recomenda√ß√£o interativa\n",
    "def create_temp_user_profile():\n",
    "    \"\"\"Cria perfil tempor√°rio do usu√°rio baseado nas sele√ß√µes\"\"\"\n",
    "    user_ratings = {}\n",
    "    for data in user_selection_state['movies'].values():\n",
    "        user_ratings[data['movie_id']] = data['rating']\n",
    "    return user_ratings\n",
    "\n",
    "\n",
    "def recommend_interactive(method, k, alpha_val):\n",
    "    \"\"\"Gera recomenda√ß√µes baseadas nas sele√ß√µes do usu√°rio\"\"\"\n",
    "    user_ratings = create_temp_user_profile()\n",
    "\n",
    "    if len(user_ratings) == 0:\n",
    "        return [], []\n",
    "\n",
    "    if method == 'Colaborativo':\n",
    "        # Simular usu√°rio tempor√°rio\n",
    "        return recommend_collab_interactive(user_ratings, k)\n",
    "    elif method == 'Conte√∫do':\n",
    "        return recommend_content_interactive(user_ratings, k)\n",
    "    else:  # H√≠brido\n",
    "        return recommend_hybrid_interactive(user_ratings, k, alpha_val)\n",
    "\n",
    "\n",
    "def recommend_collab_interactive(user_ratings, k):\n",
    "    \"\"\"Colaborativo para usu√°rio tempor√°rio\"\"\"\n",
    "    # Usar filmes avaliados para encontrar similares\n",
    "    all_scores = defaultdict(float)\n",
    "\n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        if movie_id not in movie_to_idx:\n",
    "            continue\n",
    "        movie_idx = movie_to_idx[movie_id]\n",
    "\n",
    "        if movie_idx in item_similarity_topk:\n",
    "            similar_indices = item_similarity_topk[movie_idx]['indices']\n",
    "            similar_scores = item_similarity_topk[movie_idx]['scores']\n",
    "\n",
    "            for sim_idx, sim_score in zip(similar_indices, similar_scores):\n",
    "                sim_movie_id = idx_to_movie[sim_idx]\n",
    "                if sim_movie_id not in user_ratings:\n",
    "                    all_scores[sim_movie_id] += rating * sim_score\n",
    "\n",
    "    sorted_recs = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [mid for mid, _ in sorted_recs[:k]], [score for _, score in sorted_recs[:k]]\n",
    "\n",
    "\n",
    "def recommend_content_interactive(user_ratings, k):\n",
    "    \"\"\"Conte√∫do para usu√°rio tempor√°rio\"\"\"\n",
    "    user_profile = build_user_profile_content(user_ratings)\n",
    "    similarities = cosine_similarity([user_profile], movie_embeddings)[0]\n",
    "\n",
    "    # Remover filmes j√° avaliados\n",
    "    for movie_id in user_ratings.keys():\n",
    "        if movie_id in movie_id_to_emb_idx:\n",
    "            emb_idx = movie_id_to_emb_idx[movie_id]\n",
    "            similarities[emb_idx] = -np.inf\n",
    "\n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "    recommended_movie_ids = [movies_df.iloc[idx]['movie_id']\n",
    "                            for idx in top_k_indices]\n",
    "\n",
    "    return recommended_movie_ids, similarities[top_k_indices]\n",
    "\n",
    "\n",
    "def recommend_hybrid_interactive(user_ratings, k, alpha_val):\n",
    "    \"\"\"H√≠brido para usu√°rio tempor√°rio\"\"\"\n",
    "    recs_colab, scores_colab = recommend_collab_interactive(user_ratings, k=50)\n",
    "    recs_content, scores_content = recommend_content_interactive(\n",
    "        user_ratings, k=50)\n",
    "\n",
    "    all_movie_ids = set(recs_colab) | set(recs_content)\n",
    "    combined_scores = {}\n",
    "\n",
    "    # Normalizar\n",
    "    scores_colab_array = np.array(scores_colab) if len(\n",
    "        scores_colab) > 0 else np.array([])\n",
    "    scores_content_array = np.array(scores_content) if len(\n",
    "        scores_content) > 0 else np.array([])\n",
    "\n",
    "    if len(scores_colab_array) > 0 and scores_colab_array.max() > scores_colab_array.min():\n",
    "        scores_colab_norm = (scores_colab_array - scores_colab_array.min()) / \\\n",
    "            (scores_colab_array.max() - scores_colab_array.min())\n",
    "    else:\n",
    "        scores_colab_norm = np.ones_like(scores_colab_array) if len(\n",
    "            scores_colab_array) > 0 else np.array([])\n",
    "\n",
    "    if len(scores_content_array) > 0 and scores_content_array.max() > scores_content_array.min():\n",
    "        scores_content_norm = (scores_content_array - scores_content_array.min()) / \\\n",
    "            (scores_content_array.max() - scores_content_array.min())\n",
    "    else:\n",
    "        scores_content_norm = np.ones_like(scores_content_array) if len(\n",
    "            scores_content_array) > 0 else np.array([])\n",
    "\n",
    "    colab_dict = {mid: score for mid, score in zip(\n",
    "        recs_colab, scores_colab_norm)}\n",
    "    content_dict = {mid: score for mid, score in zip(\n",
    "        recs_content, scores_content_norm)}\n",
    "\n",
    "    for movie_id in all_movie_ids:\n",
    "        score_c = colab_dict.get(movie_id, 0)\n",
    "        score_ct = content_dict.get(movie_id, 0)\n",
    "        combined_scores[movie_id] = alpha_val * \\\n",
    "            score_c + (1 - alpha_val) * score_ct\n",
    "\n",
    "    sorted_movies = sorted(combined_scores.items(),\n",
    "                        key=lambda x: x[1], reverse=True)\n",
    "    return [mid for mid, _ in sorted_movies[:k]], [combined_scores[mid] for mid, _ in sorted_movies[:k]]\n",
    "\n",
    "\n",
    "def format_recommendations_html(recs, scores, method_name):\n",
    "    \"\"\"Formata recomenda√ß√µes em HTML\"\"\"\n",
    "    html = f\"<h2>üéØ Recomenda√ß√µes - M√©todo: {method_name}</h2>\"\n",
    "    html += \"<table style='border-collapse: collapse; width: 100%;'>\"\n",
    "    html += \"<tr style='background-color: #f0f0f0; font-weight: bold;'>\"\n",
    "    html += \"<th style='border: 1px solid #ddd; padding: 8px;'>Rank</th>\"\n",
    "    html += \"<th style='border: 1px solid #ddd; padding: 8px;'>T√≠tulo</th>\"\n",
    "    html += \"<th style='border: 1px solid #ddd; padding: 8px;'>G√™neros</th>\"\n",
    "    html += \"<th style='border: 1px solid #ddd; padding: 8px;'>Score</th>\"\n",
    "    html += \"</tr>\"\n",
    "\n",
    "    for i, (movie_id, score) in enumerate(zip(recs, scores), 1):\n",
    "        movie_info = movies_df[movies_df['movie_id'] == movie_id].iloc[0]\n",
    "        title = movie_info['title']\n",
    "        genres = movie_info['genres']\n",
    "\n",
    "        html += f\"<tr style='background-color: {'#ffffff' if i % 2 == 0 else '#f9f9f9'};'>\"\n",
    "        html += f\"<td style='border: 1px solid #ddd; padding: 8px; text-align: center;'>{i}</td>\"\n",
    "        html += f\"<td style='border: 1px solid #ddd; padding: 8px;'><b>{title}</b></td>\"\n",
    "        html += f\"<td style='border: 1px solid #ddd; padding: 8px;'><i>{genres}</i></td>\"\n",
    "        html += f\"<td style='border: 1px solid #ddd; padding: 8px; text-align: center;'>{score:.3f}</td>\"\n",
    "        html += \"</tr>\"\n",
    "\n",
    "    html += \"</table>\"\n",
    "    return html\n",
    "\n",
    "\n",
    "# Output widget\n",
    "output_recs = widgets.Output()\n",
    "\n",
    "# Bot√£o de gera√ß√£o\n",
    "\n",
    "\n",
    "def on_generate_click(b):\n",
    "    with output_recs:\n",
    "        output_recs.clear_output()\n",
    "\n",
    "        # Validar sele√ß√µes\n",
    "        num_selected = len(user_selection_state['movies'])\n",
    "        if num_selected < 3:\n",
    "            print(\"‚ö†Ô∏è Por favor, selecione pelo menos 3 filmes!\")\n",
    "            return\n",
    "\n",
    "        # Obter configura√ß√µes\n",
    "        method = method_selector.value\n",
    "        k = k_slider.value\n",
    "        alpha_val = 'adaptive' if adaptive_alpha_checkbox.value else alpha_slider.value\n",
    "\n",
    "        # Se h√≠brido com adaptativo, calcular Œ± baseado no n√∫mero de filmes\n",
    "        if method == 'H√≠brido' and alpha_val == 'adaptive':\n",
    "            alpha_val = min(0.9, 0.3 + 0.6 * (num_selected / 10))\n",
    "            print(\n",
    "                f\"‚ÑπÔ∏è Œ± adaptativo calculado: {alpha_val:.2f} (baseado em {num_selected} filmes)\")\n",
    "\n",
    "        # Gerar recomenda√ß√µes\n",
    "        print(f\"üîÑ Gerando recomenda√ß√µes com m√©todo '{method}'...\\n\")\n",
    "        recs, scores = recommend_interactive(method, k, alpha_val)\n",
    "\n",
    "        if len(recs) == 0:\n",
    "            print(\"‚ùå N√£o foi poss√≠vel gerar recomenda√ß√µes. Tente selecionar mais filmes.\")\n",
    "            return\n",
    "\n",
    "        # Exibir\n",
    "        display(HTML(format_recommendations_html(recs, scores, method)))\n",
    "\n",
    "\n",
    "generate_btn = widgets.Button(\n",
    "    description='üé¨ Gerar Recomenda√ß√µes',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='300px', height='50px')\n",
    ")\n",
    "generate_btn.on_click(on_generate_click)\n",
    "\n",
    "# Layout\n",
    "display(widgets.HTML(\"<h3>üöÄ Gerar Recomenda√ß√µes:</h3>\"))\n",
    "display(generate_btn)\n",
    "display(output_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 19: Compara√ß√£o em Tabs (3 M√©todos Lado a Lado)\n",
    "\n",
    "output_tab1 = widgets.Output()\n",
    "output_tab2 = widgets.Output()\n",
    "output_tab3 = widgets.Output()\n",
    "\n",
    "tab = widgets.Tab()\n",
    "tab.children = [output_tab1, output_tab2, output_tab3]\n",
    "tab.titles = ['Colaborativo', 'Conte√∫do', 'H√≠brido']\n",
    "\n",
    "\n",
    "def on_compare_click(b):\n",
    "    num_selected = len(user_selection_state['movies'])\n",
    "    if num_selected < 3:\n",
    "        print(\"‚ö†Ô∏è Por favor, selecione pelo menos 3 filmes!\")\n",
    "        return\n",
    "\n",
    "    k = k_slider.value\n",
    "    alpha_val = min(0.9, 0.3 + 0.6 * (num_selected / 10))  # Sempre adaptativo\n",
    "\n",
    "    # Gerar para os 3 m√©todos\n",
    "    methods_configs = [\n",
    "        ('Colaborativo', output_tab1, lambda ur,\n",
    "        k: recommend_collab_interactive(ur, k)),\n",
    "        ('Conte√∫do', output_tab2, lambda ur,\n",
    "        k: recommend_content_interactive(ur, k)),\n",
    "        ('H√≠brido', output_tab3, lambda ur,\n",
    "        k: recommend_hybrid_interactive(ur, k, alpha_val))\n",
    "    ]\n",
    "\n",
    "    user_ratings = create_temp_user_profile()\n",
    "\n",
    "    for method_name, output_widget, func in methods_configs:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output()\n",
    "            recs, scores = func(user_ratings, k)\n",
    "            if len(recs) > 0:\n",
    "                display(HTML(format_recommendations_html(\n",
    "                    recs, scores, method_name)))\n",
    "            else:\n",
    "                print(\n",
    "                    f\"‚ùå N√£o foi poss√≠vel gerar recomenda√ß√µes com {method_name}\")\n",
    "\n",
    "\n",
    "compare_btn = widgets.Button(\n",
    "    description='üìä Comparar os 3 M√©todos',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='300px', height='50px')\n",
    ")\n",
    "compare_btn.on_click(on_compare_click)\n",
    "\n",
    "display(widgets.HTML(\"<h3>üìä Compara√ß√£o dos 3 M√©todos:</h3>\"))\n",
    "display(compare_btn)\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 20: Explora√ß√£o de Filmes Similares\n",
    "\n",
    "output_explore = widgets.Output()\n",
    "\n",
    "# Dropdown vazio inicialmente (preenchido ap√≥s gerar recomenda√ß√µes)\n",
    "explore_dropdown = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='Explorar:',\n",
    "    layout=widgets.Layout(width='600px'),\n",
    "    style={'description_width': '70px'}\n",
    ")\n",
    "\n",
    "\n",
    "def get_similar_movies_by_content(movie_id, k=5):\n",
    "    \"\"\"Encontra filmes similares por conte√∫do\"\"\"\n",
    "    if movie_id not in movie_id_to_emb_idx:\n",
    "        return []\n",
    "\n",
    "    emb_idx = movie_id_to_emb_idx[movie_id]\n",
    "    movie_emb = movie_embeddings[emb_idx]\n",
    "\n",
    "    similarities = cosine_similarity([movie_emb], movie_embeddings)[0]\n",
    "    similarities[emb_idx] = -np.inf  # Excluir o pr√≥prio filme\n",
    "\n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "\n",
    "    similar_movies = []\n",
    "    for idx in top_k_indices:\n",
    "        similar_movie_id = movies_df.iloc[idx]['movie_id']\n",
    "        similar_title = movies_df.iloc[idx]['title']\n",
    "        similar_genres = movies_df.iloc[idx]['genres']\n",
    "        similar_score = similarities[idx]\n",
    "        similar_movies.append((similar_title, similar_genres, similar_score))\n",
    "\n",
    "    return similar_movies\n",
    "\n",
    "\n",
    "def on_explore_change(change):\n",
    "    if change['new'] == '':\n",
    "        return\n",
    "\n",
    "    with output_explore:\n",
    "        output_explore.clear_output()\n",
    "\n",
    "        # Obter movie_id do t√≠tulo\n",
    "        movie_title = change['new']\n",
    "        movie_id = movie_title_to_id.get(movie_title)\n",
    "\n",
    "        if movie_id is None:\n",
    "            print(\"‚ùå Filme n√£o encontrado\")\n",
    "            return\n",
    "\n",
    "        # Informa√ß√µes do filme\n",
    "        movie_info = movies_df[movies_df['movie_id'] == movie_id].iloc[0]\n",
    "\n",
    "        print(f\"üé¨ Filme Selecionado: {movie_info['title']}\")\n",
    "        print(f\"üìÇ G√™neros: {movie_info['genres']}\")\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üîç Filmes Similares por Conte√∫do:\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        similar = get_similar_movies_by_content(movie_id, k=5)\n",
    "\n",
    "        for i, (title, genres, score) in enumerate(similar, 1):\n",
    "            print(f\"{i}. {title}\")\n",
    "            print(f\"   G√™neros: {genres}\")\n",
    "            print(f\"   Similaridade: {score:.3f}\\n\")\n",
    "\n",
    "\n",
    "explore_dropdown.observe(on_explore_change, names='value')\n",
    "\n",
    "# Fun√ß√£o para atualizar dropdown com recomenda√ß√µes geradas\n",
    "\n",
    "\n",
    "def update_explore_dropdown(recommended_titles):\n",
    "    explore_dropdown.options = [''] + recommended_titles\n",
    "\n",
    "\n",
    "# Widget para atualizar ap√≥s gerar recomenda√ß√µes\n",
    "update_btn = widgets.Button(\n",
    "    description='üìã Carregar √öltimas Recomenda√ß√µes',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "\n",
    "def on_update_explore(b):\n",
    "    # Pegar recomenda√ß√µes da √∫ltima gera√ß√£o\n",
    "    user_ratings = create_temp_user_profile()\n",
    "    if len(user_ratings) < 3:\n",
    "        print(\"‚ö†Ô∏è Gere recomenda√ß√µes primeiro!\")\n",
    "        return\n",
    "\n",
    "    recs, _ = recommend_interactive(method_selector.value, 10, 0.7)\n",
    "    rec_titles = [movies_df[movies_df['movie_id']\n",
    "                            == mid].iloc[0]['title'] for mid in recs]\n",
    "    update_explore_dropdown(rec_titles)\n",
    "    print(f\"‚úÖ {len(rec_titles)} filmes carregados para explora√ß√£o!\")\n",
    "\n",
    "\n",
    "update_btn.on_click(on_update_explore)\n",
    "\n",
    "display(widgets.HTML(\"<h3>üîç Explorar Filmes Similares:</h3>\"))\n",
    "display(update_btn)\n",
    "display(explore_dropdown)\n",
    "display(output_explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 21: An√°lise de Perfil do Usu√°rio\n",
    "\n",
    "output_profile = widgets.Output()\n",
    "\n",
    "\n",
    "def analyze_user_profile():\n",
    "    \"\"\"Analisa o perfil do usu√°rio baseado nas sele√ß√µes\"\"\"\n",
    "    user_ratings = create_temp_user_profile()\n",
    "\n",
    "    if len(user_ratings) == 0:\n",
    "        print(\"‚ö†Ô∏è Selecione alguns filmes primeiro!\")\n",
    "        return\n",
    "\n",
    "    with output_profile:\n",
    "        output_profile.clear_output()\n",
    "\n",
    "        # Coletar informa√ß√µes\n",
    "        genre_ratings = defaultdict(list)\n",
    "        all_ratings = []\n",
    "\n",
    "        for movie_id, rating in user_ratings.items():\n",
    "            all_ratings.append(rating)\n",
    "            movie_info = movies_df[movies_df['movie_id'] == movie_id].iloc[0]\n",
    "            genres = movie_info['genres'].split('|')\n",
    "            for genre in genres:\n",
    "                genre_ratings[genre].append(rating)\n",
    "\n",
    "        # Calcular m√©dias por g√™nero\n",
    "        genre_avg = {g: np.mean(ratings)\n",
    "                    for g, ratings in genre_ratings.items()}\n",
    "        genre_avg_sorted = sorted(\n",
    "            genre_avg.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Visualiza√ß√µes\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "        # 1. G√™neros preferidos\n",
    "        ax = axes[0]\n",
    "        top_genres = genre_avg_sorted[:8]\n",
    "        genres_names = [g for g, _ in top_genres]\n",
    "        genres_scores = [s for _, s in top_genres]\n",
    "\n",
    "        colors_palette = plt.cm.viridis(np.linspace(0, 1, len(genres_names)))\n",
    "        ax.barh(genres_names, genres_scores,\n",
    "                color=colors_palette, edgecolor='black')\n",
    "        ax.set_xlabel('Nota M√©dia', fontsize=12)\n",
    "        ax.set_title('Seus G√™neros Preferidos', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlim(0, 5.5)\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "        # 2. Distribui√ß√£o de notas\n",
    "        ax = axes[1]\n",
    "        bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "        ax.hist(all_ratings, bins=bins, color='steelblue',\n",
    "                edgecolor='black', alpha=0.7)\n",
    "        ax.set_xlabel('Nota', fontsize=12)\n",
    "        ax.set_ylabel('Frequ√™ncia', fontsize=12)\n",
    "        ax.set_title('Distribui√ß√£o das Suas Notas',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks([1, 2, 3, 4, 5])\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # 3. Resumo estat√≠stico\n",
    "        ax = axes[2]\n",
    "        ax.axis('off')\n",
    "\n",
    "        stats_text = f\"\"\"\n",
    "        ESTAT√çSTICAS DO PERFIL\n",
    "        {'='*40}\n",
    "        \n",
    "        üìä Filmes Avaliados: {len(user_ratings)}\n",
    "        \n",
    "        ‚≠ê Nota M√©dia: {np.mean(all_ratings):.2f}\n",
    "        üìà Nota M√°xima: {int(np.max(all_ratings))}\n",
    "        üìâ Nota M√≠nima: {int(np.min(all_ratings))}\n",
    "        üìè Desvio Padr√£o: {np.std(all_ratings):.2f}\n",
    "        \n",
    "        üé≠ G√™neros √önicos: {len(genre_ratings)}\n",
    "        \n",
    "        ‚ù§Ô∏è  G√™nero Favorito:\n",
    "        {genre_avg_sorted[0][0]} ({genre_avg_sorted[0][1]:.2f})\n",
    "        \n",
    "        üòê G√™nero Menos Favorito:\n",
    "        {genre_avg_sorted[-1][0]} ({genre_avg_sorted[-1][1]:.2f})\n",
    "        \"\"\"\n",
    "\n",
    "        ax.text(0.1, 0.5, stats_text, fontsize=11, verticalalignment='center',\n",
    "                family='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Recomenda√ß√£o de Œ±\n",
    "        num_ratings = len(user_ratings)\n",
    "        alpha_rec = min(0.9, 0.3 + 0.6 * (num_ratings / 10))\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üí° RECOMENDA√á√ÉO PERSONALIZADA:\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if num_ratings < 5:\n",
    "            print(f\"‚ú® Voc√™ tem poucos filmes avaliados ({num_ratings}).\")\n",
    "            print(\n",
    "                f\"   Recomendamos usar 'Conte√∫do' ou 'H√≠brido' com Œ±={alpha_rec:.2f}\")\n",
    "            print(f\"   Isso favorecer√° recomenda√ß√µes baseadas em g√™neros similares.\")\n",
    "        elif num_ratings < 10:\n",
    "            print(\n",
    "                f\"üëç Voc√™ tem um n√∫mero moderado de avalia√ß√µes ({num_ratings}).\")\n",
    "            print(f\"   O sistema 'H√≠brido' com Œ±={alpha_rec:.2f} √© ideal!\")\n",
    "            print(f\"   Balanceia bem suas prefer√™ncias com padr√µes da comunidade.\")\n",
    "        else:\n",
    "            print(f\"üåü Excelente! Voc√™ tem {num_ratings} avalia√ß√µes.\")\n",
    "            print(\n",
    "                f\"   O sistema 'H√≠brido' com Œ±={alpha_rec:.2f} aproveitar√° bem seus dados!\")\n",
    "            print(f\"   Favorecer√° recomenda√ß√µes colaborativas (sabedoria coletiva).\")\n",
    "\n",
    "        print(\"=\"*60)\n",
    "\n",
    "\n",
    "analyze_btn = widgets.Button(\n",
    "    description='üìä Analisar Meu Perfil',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='300px', height='50px')\n",
    ")\n",
    "analyze_btn.on_click(lambda b: analyze_user_profile())\n",
    "\n",
    "display(widgets.HTML(\"<h3>üë§ An√°lise de Perfil do Usu√°rio:</h3>\"))\n",
    "display(analyze_btn)\n",
    "display(output_profile)\n",
    "\n",
    "print(\"\\nüéâ Sistema Interativo Completo! Explore as funcionalidades acima.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f2_n6_semantic-search-and-data-classificat-QWY73G8N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
