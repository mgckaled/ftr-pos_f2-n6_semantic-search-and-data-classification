<!--markdownlint-disable-->

# Bloco B: Busca Semântica e Bancos de Dados de Vetores

## Índice

- [Bloco B: Busca Semântica e Bancos de Dados de Vetores](#bloco-b-busca-semântica-e-bancos-de-dados-de-vetores)
  - [Índice](#índice)
  - [Resumo Executivo](#resumo-executivo)
  - [1. Introdução à Busca Semântica](#1-introdução-à-busca-semântica)
    - [1.1 Contexto e Motivação](#11-contexto-e-motivação)
    - [1.2 Busca Lexical vs. Busca Semântica](#12-busca-lexical-vs-busca-semântica)
    - [1.3 Fundamentos Teóricos](#13-fundamentos-teóricos)
  - [2. Arquitetura de Sistemas de Busca Semântica](#2-arquitetura-de-sistemas-de-busca-semântica)
    - [2.1 Pipeline de Indexação](#21-pipeline-de-indexação)
    - [2.2 Pipeline de Busca](#22-pipeline-de-busca)
    - [2.3 Considerações de Implementação](#23-considerações-de-implementação)
  - [3. Grafos de Conhecimento](#3-grafos-de-conhecimento)
    - [3.1 Definição e Componentes](#31-definição-e-componentes)
    - [3.2 Abordagens de Construção](#32-abordagens-de-construção)
    - [3.3 Integração com Busca Semântica](#33-integração-com-busca-semântica)
  - [4. Avaliação de Sistemas de Busca Semântica](#4-avaliação-de-sistemas-de-busca-semântica)
    - [4.1 Métricas de Avaliação Offline](#41-métricas-de-avaliação-offline)
    - [4.2 Avaliação Online](#42-avaliação-online)
    - [4.3 Trade-offs e Considerações Práticas](#43-trade-offs-e-considerações-práticas)
  - [5. Bancos de Dados de Vetores](#5-bancos-de-dados-de-vetores)
    - [5.1 Algoritmos de Busca por Vizinhos Mais Próximos](#51-algoritmos-de-busca-por-vizinhos-mais-próximos)
    - [5.2 Soluções Comerciais e Open Source](#52-soluções-comerciais-e-open-source)
    - [5.3 Critérios de Seleção](#53-critérios-de-seleção)
  - [6. Tendências Contemporâneas e RAG](#6-tendências-contemporâneas-e-rag)
    - [6.1 Retrieval-Augmented Generation](#61-retrieval-augmented-generation)
    - [6.2 Hybrid Search](#62-hybrid-search)
    - [6.3 Perspectivas Futuras](#63-perspectivas-futuras)
  - [7. Conclusões](#7-conclusões)
  - [Apêndices](#apêndices)
    - [Apêndice A: Formulações Matemáticas das Métricas](#apêndice-a-formulações-matemáticas-das-métricas)
    - [Apêndice B: Exemplos de Código](#apêndice-b-exemplos-de-código)
    - [Apêndice C: Comparação de Algoritmos ANN](#apêndice-c-comparação-de-algoritmos-ann)
    - [Apêndice D: Datasets de Referência](#apêndice-d-datasets-de-referência)
    - [Apêndice E: Glossário](#apêndice-e-glossário)
    - [Apêndice F: Perguntas Frequentes](#apêndice-f-perguntas-frequentes)
  - [Referências](#referências)

---

## Resumo Executivo

Este documento apresenta uma análise abrangente dos sistemas de busca semântica e bancos de dados de vetores, tecnologias fundamentais para aplicações modernas de recuperação de informação e inteligência artificial. A busca semântica representa um paradigma que transcende as limitações das abordagens lexicais tradicionais, permitindo a recuperação de informações baseada no significado contextual em vez de mera correspondência de palavras-chave.

O documento está estruturado em sete seções principais que cobrem desde os fundamentos teóricos até implementações práticas. Inicia-se com uma contextualização histórica e conceitual da busca semântica, seguida pela descrição detalhada da arquitetura de sistemas modernos. Posteriormente, explora-se o papel dos grafos de conhecimento como estruturas complementares para enriquecimento semântico. A avaliação de sistemas recebe tratamento especial, com ênfase em métricas offline e online. A quinta seção dedica-se aos bancos de dados de vetores e algoritmos de busca por vizinhos mais próximos aproximados (ANN). As tendências contemporâneas, incluindo Retrieval-Augmented Generation (RAG), são discutidas na sexta seção.

Os apêndices complementam o texto principal com formulações matemáticas rigorosas, exemplos de código, comparações algorítmicas e um glossário técnico. Este material destina-se a estudantes, pesquisadores e profissionais que buscam compreensão aprofundada dos princípios e práticas que fundamentam sistemas de busca semântica em produção.

---

## 1. Introdução à Busca Semântica

### 1.1 Contexto e Motivação

A recuperação de informação constitui um dos problemas fundamentais da ciência da computação desde suas origens. Tradicionalmente, sistemas de busca baseavam-se em correspondência lexical, onde documentos eram recuperados mediante a presença de termos exatos da consulta. Esta abordagem, embora computacionalmente eficiente, apresenta limitações significativas relacionadas à polissemia, sinonímia e compreensão contextual.

A busca semântica emerge como resposta a estas limitações, fundamentando-se em representações vetoriais densas que capturam relações semânticas latentes. O advento de modelos de linguagem pré-treinados e técnicas de embedding transformou radicalmente o panorama da recuperação de informação, possibilitando sistemas que compreendem o significado subjacente às consultas e documentos.

### 1.2 Busca Lexical vs. Busca Semântica

**Busca Lexical** opera mediante correspondência exata ou aproximada de termos. Algoritmos tradicionais como BM25 e TF-IDF baseiam-se em estatísticas de frequência de termos, sem capturar relações semânticas. Vantagens incluem interpretabilidade e baixo custo computacional; desvantagens abrangem incapacidade de lidar com sinônimos e dependência de vocabulário controlado.

**Busca Semântica** utiliza representações vetoriais densas onde palavras ou documentos semanticamente similares posicionam-se proximamente no espaço vetorial. Esta abordagem:

- Captura relações semânticas implícitas
- Generaliza para vocabulário não observado durante treinamento
- Permite recuperação baseada em similaridade conceitual
- Requer recursos computacionais superiores para indexação e busca

### 1.3 Fundamentos Teóricos

A busca semântica fundamenta-se na hipótese distribucional de Harris (1954), segundo a qual palavras que ocorrem em contextos similares tendem a possuir significados relacionados. Modelos modernos de embedding, como BERT, RoBERTa e Sentence-BERT, implementam esta hipótese através de arquiteturas neurais profundas treinadas em vastos corpora textuais.

A similaridade semântica é tipicamente quantificada mediante métricas de distância em espaços vetoriais:

- **Similaridade Cosseno**: mede o ângulo entre vetores, invariante à magnitude
- **Distância Euclidiana**: considera tanto direção quanto magnitude
- **Distância de Manhattan**: soma de diferenças absolutas entre componentes

---

## 2. Arquitetura de Sistemas de Busca Semântica

### 2.1 Pipeline de Indexação

O pipeline de indexação compreende três etapas fundamentais:

**1. Seleção de Documentos**: Identificação e preprocessamento dos documentos a serem indexados. Esta etapa pode incluir:
- Extração de texto de fontes heterogêneas (PDFs, HTML, bases de dados)
- Segmentação em chunks apropriados ao contexto de aplicação
- Limpeza e normalização textual

**2. Geração de Embeddings**: Transformação de documentos textuais em representações vetoriais densas. Considerações técnicas incluem:
- Seleção de modelo apropriado ao domínio (geral vs. especializado)
- Dimensionalidade do espaço vetorial (tipicamente 384-1024 dimensões)
- Estratégias de agregação para documentos longos (pooling, chunking)

**3. Armazenamento em Banco de Dados Vetorial**: Persistência dos embeddings em estruturas otimizadas para busca por similaridade. Aspectos relevantes:
- Construção de índices para busca aproximada (HNSW, IVF)
- Metadados associados para filtragem e ranking
- Estratégias de particionamento para escalabilidade

### 2.2 Pipeline de Busca

A execução de consultas segue o seguinte fluxo:

**1. Transformação da Consulta**: Conversão da query do usuário em embedding utilizando o mesmo modelo empregado na indexação. Manter consistência entre indexação e busca é crucial para qualidade dos resultados.

**2. Busca por Similaridade**: Recuperação dos k documentos mais similares mediante algoritmo de vizinhos mais próximos. A escolha de k representa trade-off entre abrangência e precisão.

**3. Retorno de Resultados**: Apresentação dos documentos recuperados, frequentemente acompanhados de scores de similaridade. Pode incluir:
- Re-ranking baseado em features adicionais
- Filtragem por metadados
- Formatação contextualizada para apresentação

### 2.3 Considerações de Implementação

**Latência vs. Precisão**: Algoritmos ANN aproximados sacrificam garantias de optimalidade em prol de latência reduzida. Parâmetros como ef_construction e ef_search (em HNSW) controlam este trade-off.

**Atualização Incremental**: Sistemas em produção frequentemente requerem adição/remoção de documentos sem reconstrução completa do índice. Diferentes estruturas de dados possuem características distintas quanto a esta capacidade.

**Escalabilidade Horizontal**: Distribuição de índices em múltiplas máquinas mediante estratégias de sharding e replicação.

---

## 3. Grafos de Conhecimento

### 3.1 Definição e Componentes

Grafos de conhecimento são estruturas que representam informação mediante entidades (nós) e relações (arestas). Diferentemente de embeddings, que capturam conhecimento implícito, grafos de conhecimento codificam relações explícitas e estruturadas.

Componentes fundamentais:
- **Entidades**: Conceitos, objetos ou instâncias do domínio
- **Relações**: Conexões tipadas entre entidades (e.g., "é-um", "parte-de", "localizado-em")
- **Atributos**: Propriedades associadas a entidades ou relações
- **Ontologia**: Esquema que define tipos de entidades e relações permitidas

### 3.2 Abordagens de Construção

**Abordagem Manual**: Construção através de curadoria especializada. Vantagens incluem alta qualidade e precisão; desvantagens relacionam-se a custo elevado e escalabilidade limitada. Exemplos: Wikidata, DBpedia (parcialmente curado).

**Abordagem Automatizada**: Extração de relações mediante técnicas de NLP:
- Named Entity Recognition (NER) para identificação de entidades
- Relation Extraction para identificação de relações
- Entity Linking para resolução de ambiguidades

**Métodos Híbridos**: Combinação de curadoria manual com extração automatizada, frequentemente empregando validação humana para relações extraídas automaticamente. Esta abordagem equilibra qualidade e escalabilidade.

### 3.3 Integração com Busca Semântica

Grafos de conhecimento complementam sistemas de busca semântica através de:

**Enriquecimento de Contexto**: Expansão de consultas ou documentos com informações do grafo. Por exemplo, uma busca por "Python" pode ser contextualizada com conhecimento de que se trata de linguagem de programação vs. réptil.

**Explicabilidade**: Relações explícitas facilitam interpretação de resultados de busca.

**Navegação Estruturada**: Permitem exploração de documentos relacionados através de caminhos semânticos no grafo.

---

## 4. Avaliação de Sistemas de Busca Semântica

### 4.1 Métricas de Avaliação Offline

Avaliação offline baseia-se em datasets anotados contendo consultas e julgamentos de relevância. Métricas fundamentais incluem:

**Precisão (Precision)**: Proporção de documentos recuperados que são relevantes. Formal definição no Apêndice A.

**Revocação (Recall)**: Proporção de documentos relevantes que foram recuperados. Alta revocação indica abrangência.

**F1-Score**: Média harmônica entre precisão e revocação, balanceando ambos os aspectos.

**Mean Reciprocal Rank (MRR)**: Média dos inversos das posições do primeiro documento relevante. Privilegia sistemas que retornam documentos relevantes nas primeiras posições.

**Normalized Discounted Cumulative Gain (NDCG)**: Métrica que considera tanto relevância quanto posição, com descontos logarítmicos para posições inferiores. Amplamente utilizada em avaliação de sistemas de ranking.

**Mean Average Precision (MAP)**: Média da precisão calculada em cada posição onde documento relevante é recuperado, considerando múltiplas consultas.

### 4.2 Avaliação Online

Avaliação online ocorre em ambiente de produção com usuários reais. Técnicas incluem:

**Testes A/B**: Comparação de duas ou mais variantes do sistema mediante exposição aleatória a diferentes grupos de usuários. Métricas de interesse incluem taxa de cliques (CTR), tempo de engajamento e conversão.

**Métricas de Engajamento**:
- Click-Through Rate (CTR)
- Dwell time (tempo de permanência)
- Taxa de reformulação de consultas
- Abandonment rate

**Análise de Sessão**: Estudo de padrões de comportamento ao longo de sessões completas de busca.

### 4.3 Trade-offs e Considerações Práticas

**Relevância vs. Diversidade**: Sistemas excessivamente focados em relevância podem retornar resultados redundantes. Técnicas de diversificação (MMR - Maximal Marginal Relevance) equilibram similaridade e novidade.

**Latência vs. Qualidade**: Algoritmos aproximados reduzem latência mas podem sacrificar qualidade dos resultados.

**Custo Computacional**: Indexação e busca em espaços vetoriais de alta dimensionalidade requerem recursos significativos.

---

## 5. Bancos de Dados de Vetores

### 5.1 Algoritmos de Busca por Vizinhos Mais Próximos

**Busca Exata**: Comparação exaustiva com todos os vetores indexados. Complexidade O(n·d) onde n é o número de vetores e d a dimensionalidade. Impraticável para coleções massivas.

**Approximate Nearest Neighbor (ANN)**: Algoritmos que garantem alta probabilidade de recuperar vizinhos verdadeiramente mais próximos com complexidade sub-linear.

**HNSW (Hierarchical Navigable Small World)**:
- Constrói grafo multi-camada navegável
- Excelente trade-off precisão/velocidade
- Inserção e busca em O(log n)
- Amplamente utilizado em produção (Chroma, Weaviate, Milvus)

**IVF (Inverted File Index)**:
- Particiona espaço vetorial em clusters (voronoi cells)
- Busca restrita a clusters mais próximos
- Requer treinamento prévio para construção de clusters
- Utilizado em Faiss (Facebook AI)

**LSH (Locality-Sensitive Hashing)**:
- Hash functions que preservam similaridade
- Vetores similares mapeados para mesmos buckets
- Rápido mas menor precisão comparado a HNSW

**Product Quantization (PQ)**:
- Técnica de compressão vetorial
- Subdivide vetores em sub-vetores quantizados
- Reduz significativamente requisitos de memória
- Pode ser combinado com IVF (IVFPQ)

### 5.2 Soluções Comerciais e Open Source

**Chroma**:
- Open source, foco em simplicidade e developer experience
- Integração nativa com LangChain e frameworks de LLM
- HNSW como algoritmo padrão
- Adequado para prototipagem e aplicações de escala moderada

**Pinecone**:
- Solução managed, serverless
- Otimizado para produção em larga escala
- Latência consistente e escalabilidade automática
- Custo baseado em uso (pricing por queries e armazenamento)

**Weaviate**:
- Open source com opção managed
- Suporte nativo a GraphQL
- Módulos para vetorização automática
- Capacidades de hybrid search (vetorial + keyword)

**Milvus**:
- Open source, desenvolvido pela Zilliz
- Arquitetura cloud-native, altamente escalável
- Suporte a múltiplos índices ANN
- Adequado para cenários de bilhões de vetores

**Qdrant**:
- Open source, escrito em Rust
- Foco em performance e filtering capabilities
- API REST e gRPC
- Payload indexing para filtragem eficiente

### 5.3 Critérios de Seleção

**Escala**: Número de vetores, dimensionalidade, taxa de crescimento

**Latência**: Requisitos de latência (p50, p95, p99)

**Custo**: TCO considerando licenciamento, infraestrutura e operação

**Funcionalidades**:
- Hybrid search
- Filtragem por metadados
- Multi-tenancy
- Backup e disaster recovery

**Ecossistema**: Integração com frameworks existentes, qualidade de documentação, comunidade

---

## 6. Tendências Contemporâneas e RAG

### 6.1 Retrieval-Augmented Generation

RAG (Retrieval-Augmented Generation) representa paradigma que combina busca semântica com modelos de linguagem geradores. Fluxo típico:

1. Consulta do usuário é convertida em embedding
2. Sistema de busca semântica recupera documentos relevantes
3. Documentos recuperados são concatenados com a consulta
4. LLM gera resposta fundamentada nos documentos recuperados

Vantagens:
- Redução de alucinações mediante grounding em fontes verificáveis
- Atualização de conhecimento sem re-treinamento do LLM
- Capacidade de citar fontes e prover rastreabilidade

Desafios:
- Context window limitations dos LLMs
- Qualidade da recuperação crítica para qualidade da geração
- Latência acumulada de busca + geração

### 6.2 Hybrid Search

Combinação de busca lexical (BM25, TF-IDF) com busca semântica. Motivações:

- Complementaridade: busca lexical excelente para matches exatos; semântica para compreensão contextual
- Robustez: redução de failure modes de cada abordagem isolada

Estratégias de fusão:
- **Reciprocal Rank Fusion (RRF)**: combina rankings mediante fórmula que pondera posições
- **Linear Combination**: combina scores normalizados com pesos aprendidos
- **Cascading**: busca lexical como filtro inicial, seguida de re-ranking semântico

### 6.3 Perspectivas Futuras

**Multimodalidade**: Extensão de busca semântica para imagens, áudio e vídeo mediante embeddings multimodais (CLIP, ImageBind).

**Few-Shot Learning**: Adaptação de modelos de embedding a domínios específicos com poucos exemplos.

**Neural IR**: Integração end-to-end de retrieval e ranking mediante arquiteturas neurais.

**Privacy-Preserving Search**: Técnicas de busca vetorial preservando privacidade (homomorphic encryption, secure multi-party computation).

---

## 7. Conclusões

Este documento apresentou uma visão abrangente dos sistemas de busca semântica e bancos de dados de vetores, tecnologias que fundamentam aplicações modernas de recuperação de informação. A transição de abordagens lexicais para semânticas representa mudança paradigmática que habilita sistemas verdadeiramente inteligentes de compreensão e recuperação de informação.

Principais contribuições deste documento:

1. Contextualização histórica e teórica da busca semântica
2. Descrição detalhada de arquiteturas de sistemas em produção
3. Análise do papel complementar de grafos de conhecimento
4. Sistematização de métricas de avaliação offline e online
5. Comparação técnica de algoritmos ANN e bancos de dados vetoriais
6. Discussão de tendências contemporâneas como RAG e hybrid search

A implementação bem-sucedida de sistemas de busca semântica requer compreensão não apenas dos aspectos técnicos, mas também dos trade-offs inerentes entre qualidade, latência, custo e escalabilidade. A escolha de componentes e algoritmos deve ser guiada pelos requisitos específicos de cada aplicação.

O campo permanece em rápida evolução, com desenvolvimentos recentes em modelos de linguagem, técnicas de quantização e hardware especializado prometendo melhorias significativas em eficiência e capacidade. Profissionais e pesquisadores devem manter-se atualizados com estas tendências para projetar sistemas robustos e escaláveis.

---

## Apêndices

### Apêndice A: Formulações Matemáticas das Métricas

**Similaridade Cosseno**:
```
cos(θ) = (A · B) / (||A|| × ||B||)
       = Σ(Aᵢ × Bᵢ) / (√Σ(Aᵢ²) × √Σ(Bᵢ²))
```

**Precisão**:
```
Precision = |{documentos relevantes} ∩ {documentos recuperados}| / |{documentos recuperados}|
          = TP / (TP + FP)
```

**Revocação**:
```
Recall = |{documentos relevantes} ∩ {documentos recuperados}| / |{documentos relevantes}|
       = TP / (TP + FN)
```

**F1-Score**:
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
   = 2TP / (2TP + FP + FN)
```

**Mean Reciprocal Rank**:
```
MRR = (1/|Q|) × Σ(1/rankᵢ)
```
onde rankᵢ é a posição do primeiro documento relevante para query i.

**Normalized Discounted Cumulative Gain**:
```
DCG@k = Σᵢ₌₁ᵏ (2^{relᵢ} - 1) / log₂(i + 1)

IDCG@k = DCG@k calculado para ranking ideal

NDCG@k = DCG@k / IDCG@k
```

**Mean Average Precision**:
```
AP = (1/|rel|) × Σₖ₌₁ⁿ (P(k) × rel(k))

MAP = (1/|Q|) × Σᵢ₌₁^|Q| APᵢ
```
onde P(k) é a precisão até posição k e rel(k) é indicador binário de relevância.

---

### Apêndice B: Exemplos de Código

**Construção de Base de Conhecimento Simples**:

```python
from sentence_transformers import SentenceTransformer
import chromadb

# Inicializar modelo de embedding
model = SentenceTransformer('all-MiniLM-L6-v2')

# Documentos para indexação
documents = [
    "A busca semântica utiliza embeddings para compreender significado.",
    "Bancos de dados vetoriais armazenam embeddings de alta dimensionalidade.",
    "HNSW é algoritmo eficiente para busca aproximada de vizinhos mais próximos.",
    "RAG combina recuperação de documentos com modelos de linguagem geradores."
]

# Gerar embeddings
embeddings = model.encode(documents)

# Inicializar Chroma
client = chromadb.Client()
collection = client.create_collection(name="knowledge_base")

# Adicionar documentos
collection.add(
    embeddings=embeddings.tolist(),
    documents=documents,
    ids=[f"doc_{i}" for i in range(len(documents))]
)

print(f"Indexados {len(documents)} documentos")
```

**Execução de Busca Semântica**:

```python
# Query do usuário
query = "Como funciona a recuperação aumentada por geração?"

# Gerar embedding da query
query_embedding = model.encode([query])[0]

# Executar busca
results = collection.query(
    query_embeddings=[query_embedding.tolist()],
    n_results=3
)

# Exibir resultados
print(f"\nQuery: {query}\n")
print("Documentos mais relevantes:")
for i, (doc, dist) in enumerate(zip(results['documents'][0],
                                     results['distances'][0]), 1):
    similarity = 1 - dist  # Converter distância para similaridade
    print(f"{i}. [Similaridade: {similarity:.3f}] {doc}")
```

**Cálculo de Métricas de Avaliação**:

```python
import numpy as np

def calculate_metrics(retrieved_docs, relevant_docs):
    """
    Calcula métricas de avaliação para sistema de busca.

    Args:
        retrieved_docs: lista de IDs de documentos recuperados
        relevant_docs: lista de IDs de documentos relevantes

    Returns:
        dict com métricas calculadas
    """
    retrieved_set = set(retrieved_docs)
    relevant_set = set(relevant_docs)

    # Interseção
    true_positives = len(retrieved_set & relevant_set)

    # Precisão
    precision = true_positives / len(retrieved_set) if retrieved_set else 0

    # Revocação
    recall = true_positives / len(relevant_set) if relevant_set else 0

    # F1
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    # MRR
    first_relevant_pos = None
    for i, doc_id in enumerate(retrieved_docs, 1):
        if doc_id in relevant_set:
            first_relevant_pos = i
            break
    mrr = 1 / first_relevant_pos if first_relevant_pos else 0

    # NDCG@k
    def ndcg_at_k(k):
        relevance = [1 if doc_id in relevant_set else 0
                     for doc_id in retrieved_docs[:k]]
        dcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(relevance))

        ideal_relevance = sorted(relevance, reverse=True)
        idcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(ideal_relevance))

        return dcg / idcg if idcg > 0 else 0

    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'mrr': mrr,
        'ndcg@5': ndcg_at_k(5),
        'ndcg@10': ndcg_at_k(10)
    }

# Exemplo de uso
retrieved = ['doc_1', 'doc_3', 'doc_5', 'doc_7', 'doc_9']
relevant = ['doc_1', 'doc_2', 'doc_5', 'doc_8']

metrics = calculate_metrics(retrieved, relevant)
for metric, value in metrics.items():
    print(f"{metric}: {value:.3f}")
```

---

### Apêndice C: Comparação de Algoritmos ANN

| Algoritmo | Complexidade Busca | Complexidade Construção | Precisão | Memória | Uso Típico |
|-----------|-------------------|-------------------------|----------|---------|------------|
| **HNSW** | O(log n) | O(n log n) | Alta (95-99%) | Alta | Produção geral |
| **IVF** | O(n/k × d) | O(n × d × iter) | Média (80-95%) | Média | Datasets massivos |
| **LSH** | O(1) amortizado | O(n × d) | Baixa-Média (70-85%) | Baixa | Baixa latência |
| **PQ** | O(n) | O(n × d × iter) | Média (75-90%) | Muito Baixa | Restrições de memória |
| **Brute Force** | O(n × d) | O(1) | Perfeita (100%) | Média | Benchmarking |

**Notas**:
- n: número de vetores
- d: dimensionalidade
- k: número de clusters (IVF)
- iter: iterações de treinamento
- Precisão: recall@10 típico
- Memória: relativa ao armazenamento de n vetores de dimensão d

**Recomendações por Cenário**:

- **Alta precisão crítica**: HNSW ou combinação HNSW+PQ
- **Latência ultra-baixa**: LSH ou HNSW otimizado
- **Datasets massivos (>100M vetores)**: IVF-PQ ou ScaNN
- **Memória limitada**: PQ ou quantização
- **Prototipagem rápida**: HNSW (default em Chroma, Weaviate)

---

### Apêndice D: Datasets de Referência

**MS MARCO** (Microsoft Machine Reading Comprehension):
- 8.8M de passagens, 1M queries
- Julgamentos de relevância baseados em cliques
- Benchmark padrão para passage retrieval
- URL: https://microsoft.github.io/msmarco/

**Natural Questions**:
- Queries reais do Google Search
- Passagens da Wikipedia
- Anotações de qualidade alta
- URL: https://ai.google.com/research/NaturalQuestions

**BEIR** (Benchmarking IR):
- 18 datasets heterogêneos
- Avaliação zero-shot de modelos
- Múltiplos domínios (biomédico, financeiro, etc.)
- URL: https://github.com/beir-cellar/beir

**TREC-COVID**:
- Domínio científico (publicações COVID-19)
- Julgamentos de relevância por especialistas
- Útil para avaliar sistemas em domínios especializados

**DBpedia-Entity**:
- Busca de entidades estruturadas
- Integração de knowledge graphs
- 485 queries, 49K entidades

---

### Apêndice E: Glossário

**ANN (Approximate Nearest Neighbor)**: Algoritmo que recupera vizinhos próximos com alta probabilidade, sacrificando garantia de optimalidade por eficiência.

**Embedding**: Representação vetorial densa de dados (texto, imagem, etc.) em espaço latente de dimensionalidade reduzida.

**HNSW (Hierarchical Navigable Small World)**: Estrutura de dados baseada em grafo para busca ANN eficiente.

**Inverted File Index (IVF)**: Método de indexação que particiona espaço vetorial em clusters para acelerar busca.

**Knowledge Graph**: Estrutura que representa conhecimento através de entidades e relações explícitas.

**Locality-Sensitive Hashing (LSH)**: Família de funções hash que preservam proximidade no espaço original.

**NDCG (Normalized Discounted Cumulative Gain)**: Métrica de avaliação que considera relevância e posição dos resultados.

**Product Quantization (PQ)**: Técnica de compressão vetorial mediante quantização de sub-vetores.

**RAG (Retrieval-Augmented Generation)**: Paradigma que combina recuperação de documentos com geração por LLM.

**Semantic Search**: Busca baseada em significado contextual em vez de correspondência lexical.

**Vector Database**: Sistema de armazenamento otimizado para busca por similaridade em espaços vetoriais.

---

### Apêndice F: Perguntas Frequentes

**1. Quando utilizar busca semântica em vez de busca lexical?**

Busca semântica é preferível quando: (a) usuários expressam consultas com vocabulário variado; (b) sinônimos e paráfrases são comuns; (c) compreensão contextual é crítica. Busca lexical permanece relevante para: (a) queries com termos técnicos específicos; (b) buscas exatas (IDs, códigos); (c) restrições severas de latência.

**2. Como escolher dimensionalidade de embeddings?**

Trade-off entre capacidade representacional e eficiência computacional. Dimensionalidades típicas:
- 384: modelos rápidos e compactos (all-MiniLM-L6-v2)
- 768: padrão para BERT e similares
- 1024-1536: modelos grandes (OpenAI Ada-002, Cohere)
Dimensões maiores capturam nuances sutis mas aumentam requisitos de memória e latência.

**3. Qual banco de dados vetorial escolher?**

Depende do cenário:
- **Prototipagem**: Chroma (simplicidade, integração com frameworks)
- **Produção escala moderada (<10M vetores)**: Weaviate ou Qdrant
- **Produção larga escala (>100M vetores)**: Milvus ou Pinecone
- **Managed/Serverless**: Pinecone (priorizar operational simplicity sobre custo)

**4. Como avaliar qualidade de sistema de busca sem labels?**

Opções incluem: (a) amostragem e anotação manual de subconjunto; (b) métricas proxy como diversidade de resultados; (c) análise de engajamento (CTR, dwell time); (d) testes A/B com variantes.

**5. HNSW vs IVF: qual escolher?**

**HNSW**: melhor precision/recall, inserção dinâmica eficiente, maior uso de memória. Recomendado para maioria dos casos.

**IVF**: menor memória (especialmente com PQ), melhor para datasets ultra-massivos, requer re-treinamento para inserções em larga escala.

**6. Como lidar com documentos muito longos?**

Estratégias: (a) chunking com overlap; (b) summarization antes de embedding; (c) pooling hierárquico; (d) modelos com context window maior (Longformer, BigBird). Chunking com overlap de 10-20% tipicamente funciona bem.

**7. Busca semântica funciona para idiomas além do inglês?**

Sim, mediante modelos multilíngues (multilingual-E5, LaBSE, mBERT). Performance varia por idioma; idiomas com mais dados de treinamento (português, espanhol, francês) apresentam qualidade próxima ao inglês.

**8. Como implementar hybrid search (semântica + lexical)?**

Estratégias comuns:
- **Reciprocal Rank Fusion**: `score(d) = Σ 1/(k + rank_source(d))`
- **Weighted Combination**: `score(d) = α × score_semantic(d) + (1-α) × score_lexical(d)`
- **Cascading**: filtro lexical seguido de re-ranking semântico

Weaviate e Qdrant oferecem hybrid search nativo.

**9. Qual impacto de normalização nos embeddings?**

Normalização (vetores unitários) é crítica quando utilizando similaridade cosseno, pois elimina efeitos de magnitude. Muitos modelos já retornam embeddings normalizados. Verificar documentação do modelo específico.

**10. Como monitorar sistema de busca em produção?**

Métricas chave:
- Latência (p50, p95, p99)
- Taxa de queries sem resultados (zero-results rate)
- CTR e engagement metrics
- Distribuição de scores de similaridade
- Taxa de reformulação de queries

Ferramentas: logging estruturado, dashboards (Grafana), análise de sessões.

---

## Referências

**Artigos Fundamentais**:

1. Devlin, J., et al. (2018). "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding". NAACL.

2. Reimers, N., & Gurevych, I. (2019). "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks". EMNLP.

3. Malkov, Y., & Yashunin, D. (2018). "Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs". IEEE TPAMI.

4. Johnson, J., et al. (2019). "Billion-scale similarity search with GPUs". IEEE Transactions on Big Data.

5. Karpukhin, V., et al. (2020). "Dense Passage Retrieval for Open-Domain Question Answering". EMNLP.

**Documentação Técnica**:

6. Chroma Documentation. <https://docs.trychroma.com/>

7. Pinecone Documentation. <https://docs.pinecone.io/>

8. Weaviate Documentation. <https://weaviate.io/developers/weaviate>

9. Milvus Documentation. <https://milvus.io/docs>

10. FAISS Documentation. <https://github.com/facebookresearch/faiss/wiki>

**Livros e Surveys**:

11. Manning, C. D., et al. (2008). "Introduction to Information Retrieval". Cambridge University Press.

12. Zhao, W. X., et al. (2024). "A Survey on Large Language Models for Recommendation". arXiv:2305.19860.

13. Thakur, N., et al. (2021). "BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models". NeurIPS Datasets Track.

**Recursos Adicionais**:

14. Sentence Transformers Library. <https://www.sbert.net/>

15. Hugging Face Model Hub. <https://huggingface.co/models>

16. Papers with Code - Semantic Search. <https://paperswithcode.com/task/semantic-search>

---

**Última atualização**: 2025-11-04
**Versão**: 1.0
