# Busca Semântica: Fundamentos e Aplicações

## Sumário

1. [Introdução](#introdução)
2. [Busca Semântica com Embeddings](#busca-semântica-com-embeddings)
3. [Grafos de Conhecimento](#grafos-de-conhecimento)
4. [Avaliação de Busca Semântica](#avaliação-de-busca-semântica)
5. [Bancos de Dados de Vetores](#bancos-de-dados-de-vetores)
6. [Considerações Finais](#considerações-finais)
7. [Referências](#referências)

---

## Introdução

A busca semântica representa uma evolução fundamental nos sistemas de recuperação de informação, transcendendo as limitações das abordagens baseadas em correspondência exata de palavras-chave. Diferentemente da busca tradicional, que opera no nível sintático, a busca semântica captura o significado subjacente das consultas e documentos, permitindo recuperar informações relevantes mesmo quando não há sobreposição literal de termos.

Este documento explora quatro pilares fundamentais da busca semântica moderna: a representação vetorial através de embeddings, a estruturação do conhecimento em grafos, as metodologias de avaliação de sistemas de busca, e a infraestrutura de bancos de dados especializados para operações vetoriais em larga escala.

---

## Busca Semântica com Embeddings

### Fundamentos Conceituais

Embeddings são representações vetoriais densas de texto em espaços de dimensionalidade reduzida, onde a proximidade geométrica reflete similaridade semântica. Esta abordagem fundamenta-se na hipótese distribucional de Harris (1954), segundo a qual palavras que aparecem em contextos similares tendem a ter significados similares.

A representação vetorial permite transformar o problema de comparação semântica em um problema de geometria computacional, onde podemos aplicar métricas matemáticas bem definidas para quantificar similaridade.

### Arquitetura de Sistema de Busca Semântica

A implementação de um sistema de busca semântica com embeddings compreende três etapas principais:

#### 1. Construção da Base de Conhecimento

O processo inicia-se com a seleção e preparação de um conjunto de documentos relevantes para o domínio de aplicação. Cada documento é processado através de um modelo de embeddings pré-treinado, resultando em uma representação vetorial de dimensionalidade fixa (tipicamente entre 384 e 1536 dimensões).

Modelos contemporâneos populares incluem:
- **Sentence-BERT** (SBERT): Otimizado para tarefas de similaridade semântica
- **OpenAI text-embedding-3**: Modelos proprietários de alta dimensionalidade
- **all-MiniLM-L6-v2**: Modelo compacto e eficiente para embeddings de sentenças

#### 2. Geração de Embeddings

```python
from sentence_transformers import SentenceTransformer

# Carrega modelo pré-treinado
model = SentenceTransformer('all-MiniLM-L6-v2')

# Documentos da base de conhecimento
documents = [
    "A França é um país cuja capital é Paris.",
    "Paris tem aproximadamente 2.1 milhões de habitantes.",
    "A Alemanha é um país europeu com várias cidades importantes."
]

# Gera embeddings (vetores de 384 dimensões)
doc_embeddings = model.encode(documents)
print(f"Shape: {doc_embeddings.shape}")  # (3, 384)
```

#### 3. Processamento de Consultas (Query)

Quando um usuário submete uma consulta, o sistema executa três operações sequenciais:

**a) Transformação da Query em Embedding**

A consulta do usuário é processada pelo mesmo modelo utilizado para os documentos, garantindo consistência no espaço vetorial:

```python
query = "Qual a capital da França?"
query_embedding = model.encode([query])
```

**b) Comparação de Similaridade**

A similaridade entre a query e cada documento é calculada através de métricas de distância vetorial. A similaridade de cosseno é a métrica mais utilizada por ser invariante à magnitude dos vetores:

```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Calcula similaridade de cosseno
similarities = cosine_similarity(query_embedding, doc_embeddings)[0]

# Ordena documentos por similaridade
ranked_indices = np.argsort(similarities)[::-1]
```

A similaridade de cosseno é definida como:

```
cos(θ) = (A · B) / (||A|| × ||B||)
```

Onde A e B são os vetores de embedding, e o resultado varia entre -1 (totalmente dissimilar) e 1 (idêntico).

**c) Retorno dos Documentos Mais Similares**

O sistema retorna os k documentos com maior pontuação de similaridade:

```python
top_k = 3
for idx in ranked_indices[:top_k]:
    print(f"Similaridade: {similarities[idx]:.3f}")
    print(f"Documento: {documents[idx]}\n")
```

### Característica Fundamental

É importante ressaltar que a busca semântica não gera respostas diretas, mas recupera documentos semanticamente alinhados à consulta. A geração de respostas explícitas requer a integração com modelos de linguagem generativos (LLMs), configurando uma arquitetura de Retrieval-Augmented Generation (RAG).

---

## Grafos de Conhecimento

### Definição e Estrutura

Grafos de conhecimento, também denominados redes semânticas, são estruturas de dados que modelam informações através de grafos direcionados, onde nós representam entidades e arestas representam relações semânticas entre essas entidades. Esta representação explicita e estrutura o conhecimento de forma que máquinas possam raciocinar sobre relações complexas.

Formalmente, um grafo de conhecimento pode ser definido como uma tupla G = (E, R, T), onde:
- E é o conjunto de entidades (nós)
- R é o conjunto de tipos de relações
- T é o conjunto de triplas (sujeito, predicado, objeto)

### Exemplo Ilustrativo

Considere a seguinte representação de conhecimento geográfico:

```
França --[capital]--> Paris
Paris --[população]--> 2.1 milhões
França --[continente]--> Europa
França --[vizinho]--> Alemanha
Alemanha --[continente]--> Europa
```

Para responder à query "Qual a população da capital da França?", o sistema navega pelo grafo:
1. França --[capital]--> Paris
2. Paris --[população]--> 2.1 milhões

### Contexto Histórico e Evolução

Os grafos de conhecimento precedem as técnicas modernas de IA por décadas. Sistemas como WordNet (iniciado em 1985) e posteriormente DBpedia (2007) e Wikidata (2012) foram construídos através de curadoria manual intensiva, processo extremamente laborioso que limitava sua escala e cobertura.

Antes do advento dos embeddings neurais, os grafos de conhecimento constituíam a principal tecnologia para busca semântica, permitindo inferências através de lógica formal e raciocínio baseado em regras.

### Abordagens Híbridas Contemporâneas

Atualmente, grafos de conhecimento não são obsoletos, mas frequentemente integrados com técnicas de IA em métodos híbridos que combinam:
- **Estruturação explícita** dos grafos para relações bem definidas e raciocínio lógico
- **Flexibilidade semântica** dos embeddings para capturar nuances e lidar com dados não estruturados
- **Validação e verificabilidade** através das relações explícitas no grafo

Esta sinergia permite sistemas mais robustos que aproveitam as vantagens complementares de ambas as abordagens.

---

## Avaliação de Busca Semântica

### O Desafio da Avaliação

A avaliação de algoritmos de busca semântica apresenta complexidade intrínseca devido à natureza subjetiva da relevância e à inexistência de um único resultado correto. Múltiplos documentos podem ser relevantes para uma mesma consulta, com diferentes graus de relevância.

A questão central é: como determinar objetivamente se um sistema está entregando resultados coerentes e relevantes?

### Avaliação Offline

A avaliação offline utiliza conjuntos de teste pré-construídos contendo pares de queries e documentos relevantes esperados. Esta abordagem permite comparações reproduzíveis entre diferentes sistemas ou versões.

#### Métricas Principais

**Precision@k**

Mede a proporção de documentos relevantes entre os k primeiros resultados retornados:

```
Precision@k = (Número de documentos relevantes nos top-k) / k
```

Exemplo: Se dos 10 primeiros resultados, 7 são relevantes:
```
Precision@10 = 7/10 = 0.70
```

**Recall@k**

Mede a proporção de todos os documentos relevantes que foram recuperados nos top-k resultados:

```
Recall@k = (Documentos relevantes recuperados) / (Total de documentos relevantes)
```

Exemplo: Se existem 15 documentos relevantes e 7 foram recuperados:
```
Recall@10 = 7/15 = 0.467
```

**Mean Reciprocal Rank (MRR)**

Avalia a posição do primeiro documento relevante, penalizando sistemas que colocam resultados relevantes em posições inferiores:

```
MRR = (1/N) × Σ(1/rank_i)
```

Onde rank_i é a posição do primeiro resultado relevante para a query i.

#### Métricas Comportamentais

Além das métricas de acurácia, a avaliação pode considerar a diversidade das respostas, evitando redundância nos resultados retornados mesmo que todos sejam relevantes.

### Avaliação Online

A avaliação online ocorre em ambiente de produção, monitorando o comportamento real dos usuários. Esta abordagem captura aspectos difíceis de quantificar offline, como usabilidade e satisfação do usuário.

#### Testes A/B

Metodologia experimental onde dois sistemas de busca (A e B) operam simultaneamente com diferentes grupos de usuários. Métricas de comportamento são coletadas:

- **Taxa de cliques (CTR)**: Proporção de buscas que resultam em cliques
- **Taxa de conversão**: Proporção de buscas que levam à ação desejada
- **Tempo de engajamento**: Duração da interação com os resultados

A análise estatística determina qual sistema apresenta desempenho superior segundo os critérios estabelecidos.

### Exemplo de Avaliação

Considere uma query sobre "músicas sobre coração partido" que pode retornar múltiplos resultados relevantes:
- "Infiel" (Marília Mendonça)
- "Yesterday" (The Beatles)
- Músicas de artistas diversos

A avaliação deve considerar não apenas se os resultados são relevantes, mas também sua diversidade e a posição dos mais relevantes no ranking.

---

## Bancos de Dados de Vetores

### Motivação e Desafios de Escala

A busca semântica em escala real apresenta desafios computacionais significativos. Um sistema de produção pode conter bilhões de documentos, cada um representado por vetores de centenas ou milhares de dimensões. A busca exaustiva que compara a query com todos os documentos (complexidade O(n)) torna-se computacionalmente inviável.

Considere um cenário com 1 bilhão de documentos e embeddings de 768 dimensões. Cada comparação de similaridade requer 768 multiplicações e somas, resultando em bilhões de operações por query. Para aplicações interativas que exigem latência de milissegundos, esta abordagem é impraticável.

### Solução: Busca Aproximada

Bancos de dados de vetores empregam algoritmos especializados que implementam busca aproximada de vizinhos mais próximos (Approximate Nearest Neighbors - ANN). Estes algoritmos sacrificam pequenas quantidades de acurácia em troca de ganhos dramáticos em velocidade.

O trade-off fundamental é:
- **Busca exata**: Máxima acurácia (100% de recall), complexidade O(n), lenta
- **Busca aproximada**: Alta acurácia (90-99% de recall), complexidade sub-linear, rápida

### Algoritmos Principais

#### Hierarchical Navigable Small World (HNSW)

HNSW constrói uma estrutura de grafo em múltiplas camadas, onde cada camada contém conexões entre vetores similares. A busca inicia nas camadas superiores (mais esparsas) e progressivamente desce para camadas mais densas, navegando rapidamente pelo espaço vetorial.

Características:
- Complexidade de busca: O(log n)
- Excelente performance para recall alto
- Maior uso de memória para armazenar o grafo

#### Locality Sensitive Hashing (LSH)

LSH utiliza funções hash especialmente projetadas que mapeiam vetores similares para os mesmos buckets com alta probabilidade. A busca então opera apenas dentro dos buckets relevantes.

Características:
- Complexidade de busca: Sub-linear
- Eficiente em memória
- Adequado para dimensionalidades muito altas

### Implementações Práticas

#### Bancos de Dados Especializados

**Chroma**
- Foco em simplicidade e integração com LLMs
- Ideal para prototipagem e aplicações de médio porte
- Open-source e auto-hospedável

**Pinecone**
- Serviço gerenciado em nuvem
- Otimizado para escalabilidade e performance
- Suporte a filtragem de metadados

**Weaviate**
- Busca híbrida (vetorial + keyword)
- GraphQL API
- Suporte a múltiplos modelos de embeddings

**FAISS (Facebook AI Similarity Search)**
- Biblioteca de alta performance desenvolvida pela Meta
- Implementa múltiplos algoritmos ANN
- Adequado para pesquisa e produção

#### Bancos de Dados Tradicionais com Extensões

- **PostgreSQL + pgvector**: Adiciona capacidades vetoriais ao PostgreSQL
- **Redis Stack**: Suporte a busca vetorial em Redis
- **Elasticsearch**: Suporte a dense_vector desde versão 7.x

### Exemplo Prático com Chroma

```python
import chromadb
from sentence_transformers import SentenceTransformer

# Inicializa cliente e modelo
client = chromadb.Client()
model = SentenceTransformer('all-MiniLM-L6-v2')

# Cria coleção
collection = client.create_collection(name="documentos")

# Adiciona documentos
documents = [
    "A França é um país europeu cuja capital é Paris.",
    "Paris tem aproximadamente 2.1 milhões de habitantes.",
    "A Alemanha faz fronteira com a França."
]

embeddings = model.encode(documents).tolist()

collection.add(
    embeddings=embeddings,
    documents=documents,
    ids=[f"doc_{i}" for i in range(len(documents))]
)

# Realiza busca
query = "Qual a capital da França?"
query_embedding = model.encode([query]).tolist()

results = collection.query(
    query_embeddings=query_embedding,
    n_results=2
)

print(results['documents'])
```

### Considerações de Performance

O gráfico de trade-off acurácia-velocidade demonstra que algoritmos mais sofisticados como HNSW e ScaNN (Google) conseguem manter recall acima de 95% enquanto executam ordens de grandeza mais rápido que a busca exaustiva.

Para aplicações práticas, é essencial:
1. Definir requisitos de latência aceitável
2. Determinar o nível mínimo de recall necessário
3. Selecionar o algoritmo e configuração apropriados
4. Monitorar e ajustar parâmetros em produção

---

## Considerações Finais

A busca semântica representa um paradigma fundamental em sistemas de informação modernos, combinando avanços em aprendizado de máquina, estruturas de dados especializadas e metodologias rigorosas de avaliação. A compreensão integrada destes quatro pilares é essencial para profissionais que desenvolvem sistemas de recuperação de informação em escala.

A tendência atual aponta para arquiteturas híbridas que combinam:
- **Embeddings neurais** para capturar semântica flexível
- **Grafos de conhecimento** para relações explícitas e raciocínio
- **Bancos de dados vetoriais** para operações eficientes em escala
- **Frameworks de avaliação** rigorosos para garantir qualidade

A evolução contínua dos modelos de linguagem e algoritmos de indexação sugere que os sistemas de busca semântica continuarão avançando em capacidade e eficiência, tornando-se cada vez mais ubíquos em aplicações que vão desde motores de busca até assistentes conversacionais e sistemas de recomendação.

---

## Referências

### Artigos Fundamentais

1. Reimers, N., & Gurevych, I. (2019). "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks". *Proceedings of EMNLP-IJCNLP*.
   - Disponível em: https://arxiv.org/abs/1908.10084

2. Malkov, Y. A., & Yashunin, D. A. (2018). "Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs". *IEEE Transactions on Pattern Analysis and Machine Intelligence*.
   - Disponível em: https://arxiv.org/abs/1603.09320

3. Gionis, A., Indyk, P., & Motwani, R. (1999). "Similarity Search in High Dimensions via Hashing". *Proceedings of VLDB*.

### Documentação Técnica

4. Chroma Documentation: https://docs.trychroma.com/
5. FAISS Documentation (Meta): https://faiss.ai/
6. Sentence Transformers Documentation: https://www.sbert.net/
7. Weaviate Documentation: https://weaviate.io/developers/weaviate

### Recursos de Aprendizado

8. Anthropic - "Embeddings" (2024): https://www.anthropic.com/index/embeddings-guide
9. Google Research - "ScaNN: Efficient Vector Similarity Search": https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html
10. OpenAI - "Embeddings Documentation": https://platform.openai.com/docs/guides/embeddings

### Conjuntos de Dados e Benchmarks

11. BEIR Benchmark (Benchmarking IR): https://github.com/beir-cellar/beir
12. MS MARCO: https://microsoft.github.io/msmarco/

---

**Nota**: Este documento foi elaborado para fins educacionais no contexto de pós-graduação em Sistemas de Recuperação de Informação e Inteligência Artificial. Para aplicações práticas, recomenda-se consultar a documentação oficial das ferramentas e bibliotecas mencionadas, bem como os artigos científicos referenciados para detalhes técnicos completos.